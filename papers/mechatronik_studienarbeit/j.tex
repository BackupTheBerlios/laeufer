% TODO: Fazit, Einleitung

\section{Einleitung}

Der Läufer ist kein Monolith. Das wendige Fahrzeug kann kaum mit einem statischen Felsbrocken
verglichen werden, sondern ist in seinem Aufbau modular. Doch die Module sind nicht
in isolierten Welten; Kommunikation,
Datenübertragung zwischen ihnen ist sogar essentiell-- Blinker und Scheibenwischer können nicht, oder jedenfalls
bestenfalls in beschränktem Umfang, über ihre Zustände entscheiden, zugleich kann und will man diese einzelnen
Elemente nicht unmittelbar mit dem Fahrer verdrahten, der bei der Fahrt meist besseres zu tun hat, als Blinker
über DIP-Schalter zu konfigurieren.


Dieser Abschnitt widmet sich der Kommunikation zwischen den Elementen des Läufers, insbesondere zwischen der zentralen
Steuereinheit, hier durch einen PDA realisiert, und ihren Klienten. Verschiedene Möglichkeiten der Konstruktion
eines Datenübertragungssystems werden beschrieben und bewertet. Am Schluß erfolgt eine Beschreibung der gewählten
Kommunikations- und Gerätesteuerungsinfrastruktur.


\section{Vorüberlegung}

Bevor wir uns in die faszinierende Welt der Datenübertragung stürzen, sollten wir
für dieses Projekt eine Grundsatzentscheidung treffen: Wollen wir ein möglichst
zentral gesteuertes Netzwerk verwenden, in dem das Maximum an Entscheidungen vom PDA
getroffen wird, oder diese Entscheidungen, soweit möglich, den zu verwenden vorgesehenen SX-Platinen überlassen?


Ein Vorteil einer zentralistisch angelegten Steuerung scheint, jedenfalls bei einem Reisefahrzeug,
nur schwer erkennbar; der übliche Grund für solche Konstruktionen, die Minimierung von Redundanzen, greift
in einem Netz von konzeptionell ohnehin separaten Einheiten nicht. Somit sollten wir, um den
Datenübertragungsaufwand zu minimieren, nur mehr Konfigurationsinformationen vom PDA an die Peripherie,
und umgekehrt nur wirklich auf dem PDA notwendige Informationen versenden; letztere lassen sich zusammenfassend
als für den Fahrer gedachte Angaben-- Geschwindigkeit, Akkumulatorstand-- und zur Weiterleitung an andere
Geräte vorgesehene Informationen wie Zustände von als Peripherie angeschlossenen Lichtschaltern oder Blinker-Hebeln
beschreiben\footnote{Das Vorkommen der letztgenannten Informationen ist nicht zwingend erforderlich, falls
die Peripherie unmittelbar miteinander kommunizieren kann, z.B. durch eine Direktverbindung oder in einem
Multi-Master-Bussysstem.}(s. \ref{mw_com}).

\newpage

\section{Anforderungen an die Kommunikation}

Um von einer ``guten'' oder ``schlechten''
Lösung unseres Kommunikationsproblemes sprechen zu können, stellt sich uns somit zunächst die Aufgabe,
die zur Bemessung der gesuchten Qualität dienenden Kriterien niederzuschreiben und auszuformulieren,
nicht zuletzt gegeneinander abzuwägen, denn eine vollständige Ordnung muß sein, jedenfalls für ein
eindeutiges Urteil.

Da\ss\ diese Abwägung nicht einfach sein muß, ist einleuchtend, doch führen wir sie trotz dieser
Vorüberlegung zunächst aus, um eine Beurteilungsbasis zu bilden. Was also sind jene Meßlatten,
die wir unsrer Kommunikationslösung anlegen wollen?

        \subsection{Korrektheit}

        Zun\"achst wollen wir die folgende Forderung stellen:
	$$\text{\it Alle übertragenen Daten müssen korrekt sein.}$$

	Diese Forderung bedarf einer Konkretisierung, die wir f\"ur einzelne \"Ubertragungen wie folgt gestalten:

        \begin{enumerate}
          \item{Wenn ein Datum den Empfänger erreicht, muß es zuvor versandt worden sein}\label{j-correct-1}
          \item{Wenn ein Datum den Empfänger mehrfach erreicht, muß seine Semantik idempotent sein}\label{j-correct-2}
          \item{Wenn ein Datum den Empfänger nicht erreicht, muß der Sender davon erfahren}\label{j-correct-0}
	  \item{Nichttrivialit\"at}
        \end{enumerate}

        Von diesen vier Forderungen ist insbesondere die Nummer \ref{j-correct-2} erläuterungsbedürftig. In Kommunikationssystemen
        kommt es erfahrungsgemäß vor, daß versandte Pakete aufgrund von unangemessen ausgelösten Fehlerbehandlungen (üblicherweise,
        wenn die Bestätigung der Gegenseite einem unbemerkten Übertragunsfehler zum Opfer fiel) wiederholt versandt werden.
        Unsere obige Forderung ist auf zwei Weisen erfüllbar, nämlich zum Einen, indem verhindert wird, daß
        der Empfänger die Botschaft mehrfach erhält, oder zum Anderen, indem auf einer höhergelegenen Interpretationsebene (auf die
        somit diese Fehlerbehandlung verschoben wird) der mehrfache Empfang der gleichen Botschaft-- sofern nicht durch eine
	andere Botschaft unterbrochen-- ohne Folgen bleibt.

	\subsubsection{Erkennung von Nicht\"ubertragungen}

        Die erste Forderung ist in der Praxis auf eine sehr hohe Protokollebene verschiebbar, da wir Bidirektionalität des
	unterliegenden Kommunikationsmechanismusses fordern m\"ussen, indem wir f\"ur jede versandte Anfrage eine explizite
	Empfangsbest\"atigung verlangen (und zugleich uns versichern, da\ss\ Empfangsbest\'atigungen eindeutig sind). Zwar
	kann in der Praxis auch die Best\"atigung einer \"Ubertragung verloren gehen, obwohl die \"Ubertragung selbst erfolgreich war,
	aber eben aus diesem Grund stellten wir die dritte Forderung.

        \subsubsection{Nichttrivialit\"at}

        Die ersten drei Forderungen sind durch ein triviales Modell bereits erfüllbar, einen {\it wissentlichen Nichtverschicker},
        der kein Datum versendet und den Sender davon in Kenntnis setzt (was die erste Forderung unmittelbar und die beiden anderen
        trivial erfüllt). Die Forderung, daß überhaupt Daten übertragen werden können, müssen wir somit auch ausdrücken.


        Diese vier Forderungen \"ubernehmen wir nun als Grundforderungen. Da wir jenseits der Wunderbaren Welt der
        theoretischen Informatik operieren, werden sie natürlich nur ``in den allermeisten Fällen'' erfüllbar sein,
	da die (verschwindend geringe) Wahrscheinlichkeit eines Bitfehlers auf bearbeitenden Prozessoren jenseits
	realistischer Kontrollm\"oglichkeiten liegt,
        aber diese Aussage bezieht sich natürlich auf alle Forderungen, die wir im Verlauf der Anforderungsanalyse
	stellen werden. Zur Erf\"ullung dieser speziellen Forderungen jedoch wollen wir so geringen Spielraum wie m\"oglich lassen.

        %

        \subsection{Hinreichende Datenübertragungsrate}

        Die Geschwindigkeit, mit der Daten übertragen werden, muß den Anforderungen des Projektes genügen.


        Diese Anforderung ist, in einer derartigen Formulierung, von kaum zu übertreffender Ungenauigkeit, doch eine
        präzise Formulierung der be-nötigten Datenübertragungsrate scheint in der gegebenen Situation kaum möglich, insbesondere,
        da die Menge der anzuschließenden Geräte nicht fest gegeben ist und somit nur eine Abschätzung gemacht werden kann,
        wieviel diese dann schließlich an ``laufenden'' Informationen benötigen beziehungsweise versenden.

        Unsere Vorüberlegung jedoch, den Geräten größtmögliche Autonomie zu gewähren (also die Kommunikation auf das n\"otige
	Minimum zu reduzieren), legt nahe, daß die Bandbreite überschaubar
        bleiben kann; betrachten wir dazu als typischen Extremfall ein oft sendendes Peripherieger\"at (Aufgrund der Autonomie
	wird die Kontrolleinheit eher selten Daten versenden, da deren Versand erst vom-- im Vergleich sehr tr\"agen-- Benutzer
	angesto\ss en werden mu\ss ).

        \subsubsection{Schnelles Tachyometer}

        Typische Geschwindigkeitsmesser in \"ahnlichen Fahrzeugen werden oft nicht häufiger als zwei Mal pro Sekunde mit neuen
        Informationen versorgt. Ein auf der Zeitachse h\"oher aufl\"osendes Tachyometer k\"onnte jedoch z.B. mit der Fernseh-typischen Rate von 25 Hz
	diese Informationen versenden; h\"ohere \"Ubertragungsraten sind erfahrungsgem\"ass mit nur geringem praktischem Gewinn verbunden.
        Bei 24 Bit Datenlast (8 Bit Kennziffer, 16 Bit Information)
        wären dies folglich, in diesem Beispiel, 600 bps für dieses eine Gerät.


        Auf eine glatte Zahl aufrundend (und sehr grob nach oben absch\"atzend) erhalten wir z.B. 1024, für eine geschätzte Obergrenze von 16 Geräten also
        16384 bps im auf Datenlast eingeschränkten Übertragungs-verkehr-- Kontrolldaten ignorierend-- als theoretisches Minimum.
        Das ist, aus heutiger Sicht, nicht sehr viel, was aber, nach der Vorüberlegung, unsren Erwartungen grob entspricht.


        Bandbreite alleine reicht natürlich nicht unbedingt; die Erzählung vom mit CD-ROMs beladenen Güterzug als König der Bandbreite ist
        geläufig genug, um an eine andere häufige Forderung der Datenübertragung zu erinnern.

        %

        \subsection{Geringe Latenzzeiten und Prioritisierung von Nachrichten}

        Die Zeit, die zwischen dem Versand und dem Eintreffen eines Datenpaketes vergeht, sollte den gestellten Anforderungen gen\"ugen.


        Erneut eine eher vage Forderung, die an unsere Argumentation zur nicht-Zentralisiertheit erinnert. Wie 'minimal' die Verzögerung sein
        sollte, ist an praktischen Beispielen wohl-- abgesehen von offensichtlichen Beschränkungen-- am ehesten an einer doppelten
        Übertragung zwischen einem Schalter und einer anderen Peripherie, beispielsweise einem Scheinwerfer, erkennbar; hier machen sich
        hohe Latenzzeiten zwar nicht in einer gefährdenden, aber doch für den Fahrer ersichtlichen und irritierenden Weise
        bemerkbar. Bei einer nicht direkten Verdrahtung müßte also eine Übertragung zweier Botschaften innerhalb kurzer
        Zeit versandt werden können, bei
        direkter Kommunikationsmöglichkeit zwischen Schalter und Licht verringert sich dies auf eine einzelne Botschaft.

        Eine gute Latenzzeit für diesen Kommunikationsschritt wäre, wie im letzten Kriterium erwähnt, 0.04s; praktisch ausreichend
        wäre jedoch auch eine schlechtere Zeit von 0.1s, da, wie erwähnt, zu guter Letzt doch ``nur'' wieder das Empfinden des Fahrers bedient wird.
	Im Falle sicherheitskritischer Kommunikation jedoch, wie z.B. busgesteuerten Bremsen, sind im Allgemeinen wesentlich geringere
	Zeiten n\"otig; dies impliziert die M\"oglichkeit einer Prioritisierung von Nachrichten anhand des angesteuerten Ger\"ates.
	Da sicherheitskritische Systeme im L\"aufer entweder autark (Getriebe) oder nicht busgesteuert (Bremsen) arbeiten, werden wir
	f\"ur diese an dieser Stelle keine konkreten Forderungen einbringen. 

        Gerade an diesem Beispiel sieht man natürlich eine zuvor schon oft implizit erwähnte notwendige Anforderung, die als nächstes ausgeführt
	werden soll.

        %

        \subsection{Bidirektionalität}

        Kommunikation zwischen Peripherie und PDA sollte in beide Richtungen möglich sein.


        Diese Forderung ergibt sich unmittelbar aus der Notwendigkeit, Informationen, wie zum Beispiel die aktuelle Reisegeschwindigkeit,
        aus Peripheriegeräten auszulesen, verbunden mit der Notwendigkeit, Ger\"ate auch regulieren zu k\"onnen\footnote{Es ist praktisch nicht
	  haltbar, die Ger\"ate in Ein- und Ausgabeger\"ate zu separieren; als Beispiel sei ein Scheinwerfer genannt, der ein Durchbrennen
	  der von ihm gesteuerten Gl\"uhbirne erkennen und dem PDA mitteilen kann.}.

        %

        \subsection{Unterstützung für mehr als ein angeschlossenes Ger\"at}

        Es sollte möglich sein, mehr als ein Peripheriegerät mit dem PDA kommunizieren zu lassen.


        Eine
        Ermangelung an Bidirektionalität oder Mehr-Client-Funktionalität wäre zwar allgemein durch Verwendung mehrerer paralleler
        Kommunikationssysteme ausgleichbar, eine solche Konstruktion ist aufgrund des Mehraufwandes an Hardware und der grundsätzlich
        anderen Ansteuerung jedoch separat zu handhaben. Die angeklungene Forderung nach einem eher geringen Hardware-Aufwand läßt sich
        im Übrigen noch verallgemeinern, wie wir im nächsten Punkt sehen werden.

	Nach Diskussion mit dem L\"aufer-Team wurde die Notwendigkeit eine Unterst\"utzung von mehr als zehn separaten Ger\"aten als
	nicht gegeben eingestuft. Aus Gr\"unden zuk\"unftiger Erweiterbarkeit w\"are eine Unterst\"utzung f\"ur eine gr\"o\ss ere Zahl
	w\"unschenswert; da diese jedoch nicht n\"aher spezifiziert werden kann, wurde, um die Anzahl der m\"oglichen Protokolle an
	dieser Stelle nicht unrealistisch einzuschr\"anken, von mindestens 16 Ger\"aten ausgegangen.
        %

        \subsection{Geringe Ressourcenanforderungen}

        Das verwendete Kommunikationssystem soll ``möglichst wenig'' Hardware, Strom, und Prozessorleistung der beteiligten Kommunikationssysteme
        benötigen.



        Eine präzisere Angabe jenseits von offensichtlichen Schranken des\\ Machbaren sind hier nicht möglich; dies ist ein eher komparatives Kriterium.

        %

        \subsection{Praktische Realisierbarkeit mit gegebenen Mitteln}

        Das Kommunikationssystem muß finanziell und technisch realistisch implementierbar sein.


        Insbesondere ist, rein komparativ gesehen, eine Unterstützung seitens der Sponsoren, sowohl materiell als auch
        mit Informationen und praktischer Unterstützung ein relevantes und jedenfalls im Zweifelsfall den Ausschlag f\"ur oder gegen die
	``endg\"ultige'' Wahl einer entsprechenden Technologie gebendes Kriterium.
        Eine wesentliche Einschränkung ergab sich zudem durch den gewählten Controller, der im Läufer verwendeten Mehrzweck-Platinen, der
        nur eine sehr beschränkte Menge an Speicherplatz für Programme bietet.
        %


        \subsection{Grundvoraussetzungen}\label{j-min-req}

        Um nichts unnötig auszuschließen, wollen wir unsere Minimalforderungen derart formulieren, daß der Ausgleich fehlender
        Eigenschaften auf einer höheren Ebene prinzipiell erlaubt sein soll, endgültiger Ausschluß einer Technologie würde also nur
        erfolgen, wenn sie das Erfüllen eines der Kriterien (in einem angemessenen Maß) prinzipiell ausschließen würde.

        Wir fordern von gewählten Technologien minimal, daß sie nicht ausschließen, daß folgende Kriterien erfüllt werden:
        \begin{enumerate}
          \item{\bf Korrektheit}
          \item{{\bf Hinreichende Datenübertragungsrate}: Mindestens 16384 bps für\\ Daten alleine}
          \item{{\bf Geringe Latenzzeit}: Maximal 0.05s pro Botschaft oder 0.1s für zwei Botschaften\footnote{Diese beiden Kriterien sind sehr unterschiedlich, da z.B. über Priorisierungsmechanismen unter Umständen sichergestellt werden kann, daß Botschaften, die eingingen, jedoch weiterversandt werden müssen, eine geringere Latenzzeit haben. Auf der anderen Seite jedoch ist es-- bei einer Latenz von konstant 0.05s-- durch zusätzlichen Bearbeitungsaufwand möglich, daß dennoch ein wenig mehr als 0.1s benötigt wird. Diese Zeit betrachten wir jedoch als unerheblich und verwenden somit 0.05s als ein einfacher zu handhabendes Kriterium.}}
	  \item{\bf Prioritisierung von Nachrichten}
          \item{\bf Bidirektionalität}
          \item{\bf Unterstützung für mindestens 16 Peripheriegeräte}
          \item{{\bf Geringe Ressourcenanforderungen}: Strombedarf auf Platine abdeckbar, eventuelle Kabel maximal handelsübliche Koaxialkabel an Dicke, 
            sonstige Hardware sollte maximal soviel Masse haben wie der Rest der SX-Platine}
          \item{\bf Praktische Realisierbarkeit}
        \end{enumerate}


        Mit diesen acht Kriterien werden wir nun die verschiedenen Möglichkeiten, die sich uns zur Kommunikation bieten,
        beurteilen.

\newpage

\section{Alternativen der Kommunikationshardware}

Wir werden nun eine Reihe von Alternativen durchgehen, die uns, verbunden mit verschiedenen Vor- und Nachteilen,
Kommunikation zwischen PDA und Peripherie erlauben. Im Falle einiger dieser Technologien könnten die benötigten Anschlüsse
zwar unmittelbar auf die SX-Board aufgelötet werden, eine Kommunikation mit dem PDA würde jedoch eine Zwischenstation mit einem
als Proxy agierenden Programm (oder entpsrechender Hardware) benötigen.
Da auf den genannten Platinen ohnehin ein serieller Anschluß vorhanden ist, können sie, bei
entsprechender Programmierung, unmittelbar als ein solcher dienen (sofern die verwendete Kommunikationsmethode
der Forderung nach {\bf Bidirektionalität} genügt).\\

        \subsection{Einfache Hartverdrahtung}
        
        Die einfachsten Dinge sind oft auch die besten, daher wollen wir zunächst die Direktverbindung des PDAs mit der Peripherie über direkte
        Kabelverbindungen betrachten.

        Diese Lösung erfüllt zunächst unsere Minimalanforderungen, erlaubt beliebig viele Peripheriegeräte und ist an Bandbreite und Latenz nur durch
        den Systembus des SX-Controllers begrenzt. Doch schon hier stellt sich die erste Frage: Wie verbindet man die Controller direkt an ihrem
        Systembus? Ein Arbitrierungsmechanismus müßte herbei, um den Verlust von \"Ubertragungen zu verhindern\footnote{Dritte Forderung
	  der Korrektheit}. Aber
        damit haben wir schon wesentlich mehr als eine einfache Hartverdrahtung; wenn wir jedoch unser Modell beibehalten wollen, bliebe uns nur,
        die Peripherie direkt mit den Eingängen der SX-Ports zu verbinden. Dies würde natürlich die Anzahl der anschließbaren Peripheriegeräte unmittelbar
        beschränken-- die notwendigen 16 Geräte sollten jedoch kein prinzipielles Problem darstellen.

        Eine direkte Verbindung erzwingt jedoch einen unnötig komplexen Kabelbaum (wenn zwei Peripheriegeräte direkt
        nebeneinander liegen, ist es nicht ausreichend, sie miteinander zu verbinden-- jedes von ihnen muß einzeln verkabelt sein). Eine derartige
        Konstruktion würde Masse am Läu-fer kosten und wäre fehleranfällig; dennoch verbleibt die Hartverdrahtung als eine, wenn auch nicht
        optimale, Möglichkeit. Ihr Hauptvorteil, die hohe Geschwindigkeit und geringe Latenz (die durch zwischengeschaltete Verstärker
        jedoch geringfügig leiden dürfte) ist im Projektrahmen zwar interessant, aber nicht fundamental ausschlaggebend.
        
        %

        \subsection{Drahtlose Kommunikation}

        Die Zusammenfassung aller drahtlosen Kommunikationsmittel in einer einzigen Sektion legt das Urteil über diese natürlich bereits nahe,
        daher will ich es ohne Umschweife ausformulieren.

        Drahtlose Kommunikation benötigt mehr Leistung als hartverdrahtete Kommunikation und ist störungsanfälliger; da sie kein geschlossenes
        System erlaubt (jedenfalls nicht ohne Kryptographie, die jenseits der Schranken der praktischen Realisierbarkeit lag), ist
        somit auch die Erfüllung der Forderungen der Korrektheit nur schwerlich vorstellbar.
        %

%       \subsection{Universal Serial Bus (USB)}
        %
%% -- fixme -- %%

%       \subsection{IEEE 802}
        %
%% -- fixme -- %%

%       \subsection{IEEE 1394 ,,Firewire''}
        %
%% -- fixme -- %%

%       \subsection{Profibus}
        %
%% -- fixme -- %%

%       \subsection{InterBus}
        %
%% -- fixme -- %%

        \subsection{Actuator Sensor Interface (AS-i)}
        Das 1993 entworfene Actuator Sensor Interface des AS-i Konsortiums
        ist ein Master-Slave-System mit bis zu 31 Slaves, das sich insbesondere
        durch eine sehr geringe Komplexität auszeichnet. Tatsächlich erfüllt
        es alle Anforderungen, die von uns an ein solches Netzwerk gestellt werden;
        sein einziger wesentlicher Nachteil ist die Beschränkung der Größe des Ein- und
        Ausgangskanals auf je 4 Bit, was zu einer Verwendung von fragmentierter
        Datenübertragung zwingt.\\
        Da wir jedoch zu spät von seiner Existenz erfuhren und nicht unmittelbar
        mit Unterstützung seitens der Sponsoren rechnen konnten, muß seine
        Bedeutung auf eine Aufführung in dieser Ausarbeitung beschränkt bleiben.
        %
%% -- fixme -- %%

        \subsection{Controller Area Network (CAN)}

        Das Controller Area Network, 1986 von der Robert Bosch AG zur
        Multi-Master-Kommunikation im Auftrag von Mercedes-Benz entwickelt,
        erfreut sich heutzutage einer wachsenden Beliebtheit auch bei
        anderen KFZ-Herstellern wie BMW, Porsche, Fiat etc., wird
        aber auch außerhalb der Automobilbranche genutzt.


        Das CAN-Protokoll ist ein reines Kommunikationsprotokoll
        (welches auch vielfach bereits in Hardware implementiert
        wurde), bezieht sich also nicht auf die verwendeten
        physikalischen Transfermedien und die darübergelegene
        ``Objektschicht'' (wie die darüberliegenden Schichten
        gem. OSI-Modell von der CAN-Spezifikation genannt
        werden). Zur Zeit existieren zwei relevante, im gleichen Netz
        ineroperable Protokollversionen:

        \subsubsection{CAN 1.2}
        Version 1.2 des Protokolls stellt Mechanismen zur
        Bus-Arbitrierung, Erkennung und Korrektur fehlerhafter
        Datenübertragungen und einen vorgesehenen Adressraum von 11 Bits
        für angeschlossene Geräte zur Ver-fügung; aufgrund einer
        protokollbedingten Einschränkung ist jedoch ``nur''
        eine Adressierung von 2032 ($= 2^{11} - 16$) Busteilnehmern möglich.\\
        Ein zur unmittelbaren Datenübertragung verwendetes CAN-Frame
        (der Version 1.2) maximaler Größe beinhaltet 8 Bytes an Daten
        und belegt (inkl. Inter-frame space, dem Abstand zweier
        Frames) 111 Bit.\\
        Das Protokoll selbst läßt die genaue Hardware-Implementierung
        offen, gängig sind jedoch Raten von 1 Mb/s bei minimalem
        Verdrahtungsaufwand, was die Minimalanforderungen mehr als
        abdeckt.


        \subsubsection{CAN 2.0}
        Diese Protokollversion unterscheidet sich von CAN 1.2
        lediglich in der optionalen Verfügbarkeit von
        29-Bit-Bezeichnern\footnote{Die Einführung dieser Erweiterung
        begründet sich historisch aus von der American Society of
        Automative Engineers (SAE) gestellten Anforderungen}.

        %

        \subsection{Vehicle Area Network (VAN)}

        Dieses Netzwerk, in direkter Konkurrenz zum CAN, wurde in Frankreich entwickelt, scheint sich jedoch keiner vergleichbaren
        Popularität zu erfreuen. Ebenfalls als Multi-Master-fähiges
        Protokoll entworfen, wurde es 1994 ISO-standardisiert, hat
        jedoch keine (uns relevant erscheinenden) markanten Vorteile
        gegenüber seinem Konkurrenten.

        %

        \subsection{Konklusion}
Schlussendlich fiel die Wahl auf das CAN-Protokoll, nicht nur aufgrund der guten Abdeckung der Anforderungen, sondern auch
und insbesondere wegen der Unterstützung bei dessen Verwendung, die seitens der Sponsoren des Läufer-Projektes geleistet wurde und des
allgemeinen Interesses an einem in der Industrie derart verbreiteten Protokoll.


%% -- fixme -- %%
\newpage

\section{Übrige Anforderungen und Umsetzung}
        \subsection{Bereits durch CAN abgedeckte Anforderungen}
	Wir untersuchen zun\"achst, welche der konkreten gestellten Anforderungen bereits durch
	CAN selbst abgedeckt werden:

        \begin{enumerate}
          \item{{\bf Korrektheit}: Wir erinnern uns an die vier geforderten Eigenschaften:
            \begin{enumerate}
            \item{{\it Wenn ein Datum den Empfänger erreicht, muß es zuvor versandt worden sein}:
              Wird trivial von CAN erfüllt.}
            \item{{\it Wenn ein Datum den Empfänger mehrfach erreicht, muß seine Semantik idempotent sein}:
              Die Prämisse gilt in CAN nicht, somit muß die Konklusion nicht erfüllt werden.}
            \item{{\it Wenn ein Datum den Empfänger nicht erreicht, muß der Sender davon erfahren}:
              Diese Implikation wird von CAN nicht selbst erfüllt; ein erweiterndes Protokoll müßte
              sie sich zur Aufgabe setzen. In unmittelbarem Zusammenhang damit ergibt sich ein praktisch
              relevantes Problem: Kurzzeitige Leitungsstörungen können den Verlust einzelner Botschaften zur
              Folge haben, ohne, daß die Kommunkation unbedingt zusammengebrochen wäre. Diese Situation
              erfordert Neuversendungen der alten Daten, wird jedoch nicht von CAN abgedeckt, da dieses
              Protokoll keine empfangenen Sendungen quittiert.
	    \item{Daten\"ubertragung mu\ss\ nichttrivial sein}
            }
            \end{enumerate}
          }
          \item{{\bf Hinreichende Transferrate}: Marktübliche Implementierungen liefern 1 Mb/s; bei Wahl eines hinreichend
            intelligenten Protokolles sollte die gewünschte Mindest-Transferrate somit zu erreichen sein:
            Eine solche Basis-Übertragungsrate liefert,
            bei zwischen 111 ($1 \times 8$) und 440 ($8 \times 1$) Bits
            für 8 Byte, also zwischen knapp 580000 und 145000 bps alleine für
            Daten \footnote{falls keine Fehlerbehandlung nötig ist}, weit mehr,
            als gefordert.
          }
          \item{{\bf Geringe Latenzzeiten}:
            Die Latenzen in CAN sind, wie allgemein in Bus-Systemen üblich, minimal. Bei schlechtest
            möglichen Frames liegt die Latenz unter 0.00012s, was darüberliegenden Protokollen viel
            Freiraum einräumt.
          }

          \item{{\bf Bidirektionalität}:
            CAN bietet, als Multi-Master-System, verschiedenste Möglichkeiten multidirektionaler Kommunikation.
          }

          \item{{\bf Unterstützung mehr als eines Clients}: Wie angedeutet, sieht CAN 1.2 eine Adressierung von bis zu 2032 Clients vor;
            tatsächlich könnte durch spätere Auswahl auf den Empfangenen Daten diese Menge beliebig erweitert werden
            (was im Rahmen dieses Projektes jedoch einer Begründbarkeit entbehren würde).}

          \item{{\bf Geringe Ressourcenanforderungen}: Die aufgeführten Bedingungen (Subesektion \ref{j-min-req}) werden von der handelsüblichen Hardware
            uneingeschränkt erfüllt.
          }

          \item{{\bf Praktische Realisierbarkeit}: Bei Verwendung dieser Technologie erhielten wir Unterstützung durch unsre
            Sponsoren (von denen sogar eine entsprechende Empfehlung ausgesprochen worden war).
          }
        \end{enumerate}

        \subsection{Verbleibende Anforderungen}
        Die wesentliche verbleibende Anforderung ist somit die dritte Forderung der Korrektheit, die eine Notifikation
        des Senders im Falle einer fehlgeschlagenen Übertragung voraussetzt; weitere Eigenschaften, wie ein verallgemeinertes
        Initialisierungsprotokoll erscheinen zwar ebenfalls hilfreich, können jedoch auf einer höheren Ebene nachgereicht werden.


\newpage

\section{Alternativen für das Kommunikationsprotokoll}

Die Wahl des Bus-Systems (für das wir, auf externe Empfehlung hin, CAN-Controller vom Typ
MCP2510 der Firma Microchip Technology Inc.
verwenden), war somit gefallen. Diese liefern die bereits zuvor für diverse Abschätzungen verwendete Übertragungsrate
von 1 Mb/s.

Es stand jedoch noch die Wahl des auf CAN aufsetzenden Datenprotokolles offen; zwar lieferte CAN selbst bereits, wie
beobachtet, die notwendigsten Eigenschaften zur Datenübertragung, doch Übertragung auf reinem CAN ist sehr primitiv, erlaubt
nur, Datenpakete ``an alle interessierten Zuhörer'' zur Verfügung zu stellen\footnote{
Die zuvor erw\"ahnten ``Adressierungsmechanismen'' sind somit nur Konventionen des Auslesens.
}. Zur gerichteten, sequentiellen Datenübertragung
und zum Geräte-Management bedarf es weiterer Konventionen, in Form von Datenübertragungsprotokollen.\\
Betrachten wir einige der üblichen Möglichkeiten zur Implementierung eines Kommunikationsprotokolles:


        \subsection{Smart Distributed System (SDS)}
        Das Smart Distributed System \cite{SDS}, von Honeywell Inc. entwickelt, ist ein primär zur Automatisierung von
        Produktionssystemen gedachtes Komplettpaket von Sensoren und Aktuatoren, das bis zu 64 physikalische Einheiten miteinander
        verknüpfen kann. Aufgrund seiner Propriarität, des geringen Bekanntheitsgrades in Europa und der wenig
        fahrzeugtechnischen Orientierung wirdmeten wir diesem System keine besondere Aufmerksamkeit.


        \subsection{CANopen}
        Das CANopen-Protokoll \cite{CANopen} ist ein Protokoll, das sich durch Reichtum an Features und Umfang auszeichnet und seit 1995
        von der internationalen
        {\it Can in Automation}- Gruppe (CiA) gepflegt wird. CANopen bietet verschiedenste Kommunikationsmodelle und selbst erweiterte
        Funktionalität wie die automatische Konfiguration von Busteilnehmern oder die Synchronisierung von Zeitmessungsgeräten oder
        synchrone Client-Server-\\Kommunikation ``auf Antrag'' über einen dedizierten Server (den sogenannten Service-Data-Object-Server).\\
        Zentral für dieses Protokoll ist der Begriff des ``Object dictionary'', eines zentralen Repositoriums, dessen Inhalt
        durch alle Kommunikationsteilnehmer, ihre konfigurierbaren Felder und deren Typen\footnote{mit einem sehr eingeschränkten, maschinell
          orientierten Typbegriff, wie in Laufzeitsystemen verbreitet} gebildet wird.\\
        Schon angesichts dieser selbstbezüglichen Eigenschaften wird die grosse Mächtigkeit dieses Protokolles klar, zugleich jedoch
        ist erkennbar, daß es weit mehr bietet als für diesen Bereich nötig und, insbesondere, bei einer manuellen Implementierung
        auf unsrer beschränkten Hardware unnötigen Overhead in Daten- und Programmspeicher verursachen würde. 


        \subsection{DeviceNet}
        DeviceNet \cite{DeviceNet}, ein mit SDS vergleichbares Protokoll der {\it Open DeviceNet Vendor Association}, ist, wie
        dieses, primär zu Automationszwecken gedacht. Die Spezifikation dieses Protokolles ist jedoch nur auf
        Bestellung gegen Entgelt erhältlich; da der Einsatz von DeviceNet-spezifischen Hardwarekomponenten keinen relevanten
        Vorteil zu versprechen schien, wurde von einer genaueren Evaluierung von DeviceNet abgesehen.


        \subsection{Eigenentwicklung}
        Zuletzt blieb noch die Möglichkeit eines selbst entworfenen, auf CAN aufsetzenden Protokolles. Diese
        hatte zwar zunächst den unmittelbaren Nachteil, noch nicht entworfen worden zu sein, in Anbetracht der Nicht-
        verfügbarkeit existierender Implementierungen der anderen genannten Protokolle für die von uns gewählte Plattform jedoch andererseits
        den Vorteil, mit moderaten Entwurfsaufwand den Implementierungsaufwand den\\ Bedürfnissen des Läufers gegenüber angemessen
        gestaltbar zu sein. Die wesentlichste Schwachstelle dieser Vorgehensweise war die h\"ohere Fehleranf\"alligkeit einer
	Eigenimplementierung.


        \subsection{Fazit}
        Schlußendlich fiel unsre Entscheidung schon sehr früh auf eine eigene Entwicklung, da der Aufwand für eine vollständige
        Implementierung bereits existierender Protokolle (soweit ihre Spezifikationen überhaupt öffentlich verfügbar waren) unseres
        Ermessens nach wesentlich höher gewesen wäre, wohingegen die Verwendung einer eingeschr\"ankten Version eines dieser Protokolle keine
        merklichen Vorteile gegenüber einem eigenen solchen erwirkt hätte. Eine (entsprechend fehlertr\"achtige) Eigenimplementierung
	w\"are in jedem Fall n\"otig, auch, da nach unserem Kenntnisstand keine frei verf\"ugbare Implementierungen der genannten Protokolle f\"ur den
	SX-Prozessor verf\"ugbar sind.


\newpage

\section{Das Läufer-Protokoll für den CAN-Bus} 

Die Aufgaben des resultierenden Protokolls m\"ussen wir nun wieder auf die bereits zuvor verwendeten Protokollkriterien zurückführen.
Hierbei sind die Eigenheiten des CAN-Protokolls zu beachten; die Protokolle haben also nicht nur zur
Aufgabe, unsere Korrektheitsforderungen zu erfüllen, sondern auch, eine gute Anbindung an CAN zu bieten-- wobei es sich von diesem
natürlich aus Gründen eines klaren Designs zumindest in seiner Spezifikation hinreichend weit abtrennen sollte.\\

\subsection{Grunds\"atzliche Protokollstruktur}

Um die Komplexit\"at eines solchen Protokolles zu reduzieren, beschlossen wir eine Aufspaltung in
zwei Protokolle, in denen eines die grundsätzliche Kommunikation und das
andere einfaches Session-Management mit Timeouts spezifizieren w\"urde. Trotz des zu erwartenden Overheads
schien uns dieses Design wartbarer als ein komplett integriertes.\\

Eine zunächst noch offene Frage war, ob Multi-Mastering verwendet werden sollte,
eine von CAN angebotene M\"oglichkeit. Der offensichtliche Vorteil war die
Verringerung von Latenzzeiten von Meldungen von der Peripherie an den PDA, der
Nachteil eine h\"ohere Komplexit\"at und m\"ogliche Blockierungen des Busses
durch ungez\"ugelten prioritisierten Schreibverkehr auf dem Bus.
Da die Blockierung des Busses jedoch in einem stark eingeschr\"ankten
System allgemein gut zu isolieren ist (und der tats\"achliche Gebrauch des
Multi-Masterings f\"ur viele Ger\"ate unn\"otig ist), schien eine Verwendung
dieser M\"oglichkeit zur schnellen Meldung von Fehlerzustands\"uberg\"angen sinnvoll (wenn auch wir
Protokollseitig die Kommunikationsm\"oglichkeiten aus Gr\"unden der Fehlererkennung einschr\"ankten).

\subsection{Struktur des Netzes}

Aus theoretischer Sicht ist das Netz von sternförmiger
Topologie, mit dem PDA als Zentrum; diese Vereinfachung des
Protokolls schien uns hilfreich, um die vollst\"andige Trennung
(und somit Isolation von Fehlern) auf einzelne Ger\"ate zu beschr\"anken.
Die tatsächliche Verdrahtung hingegen kann natürlich
beliebig im Rahmen des von CAN Ermöglichten erfolgen.


        \subsection{Die beiden Protokollschichten}
        Die beiden Protokolle, mit Namen {\it LLO} und {\it LLZ} (``Läufer Layer One'' bzw. ``Zero''), nehmen also
        zueinander signifikant andere Aufgaben wahr:

                \subsubsection{Aufgaben des LLO-Protokolls}
                Die Aufgaben des LLO-Protokolls umfassen die folgenden:
                \begin{enumerate}
                  \item{Adressierung der Klienten}
                  \item{Verpackung der zu übertragenden Daten in Pakete des Data Link/ Network Layer (speziell CAN)}
                  \item{Busmastering}
                \end{enumerate}


                \subsubsection{Aufgaben des LLZ-Protokolls}
                Das LLZ-Protokoll übernimmt folgende Teilaufgaben:
                \begin{enumerate}
                  \item{Session-Management}
                  \item{Erfüllung des ersten Korrektheitskriteriums}
                \end{enumerate}
                Eine ``Sitzung'' im für uns relevanten Sinn erstreckt sich hierbei von Aktivierung bis Deaktivierung
                des Läufers.

                \subsubsection{Der sichere Betriebszustand}
                Beiden Protokollen ist ein Konzept zu Eigen, das den Namen ``sicherer Betriebszustand'' trägt, sich
                auf Klienten im Bus bezieht und
                individuell für jedes angeschlossene Gerät definiert werden muß. Dieser sichere Betriebszustand
                ist von angeschlossenen Geräten im Fehlerfall einzunehmen, insbesondere, wenn die Kommunikation nach
                außen abreißt.
\newpage

\section{Der Bezug zum OSI-Schichtenmodell}
Als kurzer Einschub soll hier noch einmal auf das OSI-Schichtenmodell
eingegangen werden, das zwar keinen leitenden Einfluß auf das Protokolldesign
hatte, wohl aber zur nachträglichen Klassifizierung verwendet werden kann.\\
In dem verwendeten Kommunikationssystem werden die Ebenen wie folgt belegt:

\begin{itemize}
  \item {{\bf Schicht 1: Physical Layer}: Diese Schicht findet sich in Verdrahtung, dem MCP2510, dem SX-Microcontroller, und den
    dazwischenliegenden Verbindungen.}
  \item {{\bf Schicht 2: Data Link Layer}: Die Fehlererkennung dieser Schicht ist im CAN-Protokoll spezifiziert, findet sich entsprechend
    physikalisch auf dem MCP2510.}
  \item {{\bf Schicht 3: Network Layer}: Ansteuerung der Komponenten wird, im Rahmen der CAN-spezifizierten Adresskonventionen,
    von einer Implementierung des LLO-Protokolls realisiert. Die wesentliche Arbeit dabei wird durch Filtermechanismen im MCP2510
    implementiert.}
  \item {{\bf Schicht 4: Transport Layer}: Die Zerteilung in einzelne Pakete führt die LLO-Implementierung durch.}
  \item {{\bf Schicht 5: Session Layer}: Die Registrierung von Busteilnehmern und Timeout-Checks bei der Kommunikation werden
    von LLZ realisiert.}
  \item {{\bf Schicht 6: Presentation Layer}: Nach- bzw. Vorbearbeitung der übersandten Daten wird von Geräten und Treibern
    individuell gelöst und ist nicht Teil der hier beschriebenen Kommunikationsschicht.}
  \item {{\bf Schicht 7: Application Layer}: Die tatsächliche Durchreichung der Informationen an den Anwender, ihre optische
    Aufbereitung, automatische Beantwortung oder, allgemeiner, Versendung, findet sich in den anderen Teilen dieser Ausarbeitung
    beschrieben.}
\end{itemize}
    

\newpage

\section{Das LLO-Protokoll}
Das Protokoll geht davon aus, dass versandte Daten ``ganz oder gar nicht'' ankommen, gemäß unseren Korrektheitsforderungen
(die ja zu zwei Dritteln schon von CAN erfüllt wurden). In diesem Rahmen stellt es zusätzliche Sicherheitsmechanismen
und ein Multi-Master-Protokoll, das sich auf CAN implementieren
läßt\footnote{Die vollständige Protokollspezifikation findet sich als Anhang (Sektion {\ref{llo-proto}}).}.

        \subsection{Struktur des Protokolls}

        Das LLO-Protokoll ist ein prinzipiell Multi-Masterfähiges Protokoll, das die Nutzung der Möglichkeiten von Multi-Master-
        Sendungen jedoch auf asynchrone Notifikationen einschränkt. Somit existiert ein tatsächlicher Master in diesem Netzwerk,
        der als Controller bezeichnet wird; er erhält zugleich eine der 32 im Bus verfügbaren Adressen (1) fest zugewiesen.
        Eine weitere Adresse ist für explizite Broadcasts (z.B. für eine totale Systemabschaltung im Falle der Entfernung des
        den Controller steuernden PDAs) reserviert, was 30 Adressen für Busteilnehmer läßt.\\
        Gerichtete und Broadcast-Adressierung sind somit möglich; die Länge der übertragenen Daten ist zudem durch LLO nicht
        eingeschränkt.\\

        Fassen wir einmal kurz die vom Protokoll vorgesehenen Befehle mit ihren relativen Prioritäten zusammen:
        \vspace{0.3cm}\\
        \begin{tabular}{cclp{7cm}}
        {\bf Kürzel} & {\bf Priorität} & {\bf Sender} & {\bf Bedeutung} \\
        \hline
        {\tt SYS} & 3 & Alle            & Fehlermeldungen, Fehlerbehandlung \\
        {\tt ACK} & 3 & Alle            & Bestätigung nach Übertragung \\
        {\tt KAL} & 3 & Controller      & Keep-Alive-Signal (s. \ref{jd-llo-kal}) \\
        {\tt STX} & 2 & Controller      & Controller $\rightarrow$ Client- Transfer \\
        {\tt RTX} & 1 & Client          & Client $\rightarrow$ Controller- Transfer \\
        {\tt NOP} & 0 & Controller      & Busfreigabe \\
        \end{tabular}
        \vspace{0.3cm}

        Betrachten wir nun die wesentlichen Eigenschaften des Protokolls: 

        \subsubsection{Sicherheitsmechanismen gegen Datenverlust}
        Um den Verlust von Datenpaketen wenigstens in den häufigsten Fällen zu bemerken, wird mit jeder Übertragung
        der Inhalt eines 4-Bit-Sequenzzählers versandt, der (bis auf {\tt SYS}-, {\tt KAL}- und {\tt NOP}-Nachrichten) zudem bei jeder
        nicht-Broadcast-Botschaft um eins erhöht wird. Stellt nun der Controller oder der Client beim
        Empfang einer Botschaft ein Nicht-Übereinstimmen der Sequenznummern fest, kann er davon ausgehen, einige Botschaften verloren zu
        haben und diese neu anfordern.\\
        Diese Methode greift offensichtlich nicht immer; bei einer hypothetisch normalverteilten Datenverlustrate von $p$
	ist die Wahrscheinlichkeit,
        genau 16 Nachrichten hintereinander zu verlieren, jedoch genau
        $p^{15} * (1-p)$, im Falle von Vielfachen von 16 (also allen Möglichkeiten, in denen ein Datenverlust nicht
        bemerkt würde) somit, für die Aufsummierung der Wahrscheinlichkeiten des Verlustes an der $n$ten Stelle
        $$p_n = p^{16n + 15} * (1-p)$$
        und im Limes
        \begin{equation}
          \begin{split}
            \lim_{n \rightarrow \inf} \sum_{k = 0}^n p_k &= (1-p) * p^{15} * \lim_{n \rightarrow \inf} \sum_{k=0}^n p^{16n}\\
            & = (1-p) * p^{15} * \lim_{n \rightarrow \inf} \frac{p^{16(n+1)} - 1}{p^{16} - 1}\\
            & = - \frac{(1-p) * p^{15}}{p^{16} - 1}
          \end{split}
        \end{equation}

        Entsprechend ist bei einem ``realistischen'' normalverteilten Datenverlustwert die Wahrscheinlichkeit für einen kompletten Ausfall
        dieses Mechanismusses vernachlässigbar; selbst bei einem Störfaktor von 0.1 läge die Wahrscheinlichkeit noch bei
        unter $10^{-15}$, sogar ein Störfaktor von 0.9 könnte nur in knapp 2.6\% der Fälle einen Totalausfall dieses
        Sicherungsmechanismusses bewirken:

	\vspace{0.3 cm}

	\begin{tabular}{l|l}
	  {\bf $p$} & {\bf Datenverlustwahrscheinlichkeit} \\
	  \hline
	  $0.001$ & $ 0.999 * 10^{-45}$ \\
	  $0.01$ & $ 0.99 * 10^{-30}$ \\
	  $0.1$ & $ 0.9 * 10^{-15}$ \\
	  $0.15$ & $ 0.37221 * 10^{-12}$ \\
	  $0.2$ & $ 0.262144 * 10^{-10}$ \\
	\end{tabular}
	\vspace{0.3 cm}

	Tats\"achlich treten in der Praxis jedoch oft sequentielle Ausf\"alle auf, in denen ein vorheriger Ausfall
	die Wahrscheinlichkeit f\"ur einen erneuten Ausfall erh\"oht. Die Berechnung der Ausfallwahrscheinlichkeit
	hierf\"ur ist aufwendiger, im Allgemeinfall jedoch aufgrund des stochastischen Zusammenhanges aller relevanten
	Zufallsvariablen nicht m\"oglich.

	F\"ur allgemein geringe Fehlerwahrscheinlichkeiten ist eine solche Steigerung der Fehlerwahrscheinlichkeit aufgrund
	eines vorhergehenden Fehlers mit einer Verschlechterung des Verhaltens verbunden, die mit gr\"o\ss eren Sequenznummermengen
	besser aufgefangen werden k\"onnte.

        \subsubsection{Keep-Alive}\label{jd-llo-kal}
        Dies alles ist im Falle einer kompletten Unterbrechung der Datenleitung jedoch wenig hilfreich. In diesem
        Fall kommt das Keepalive-Signal zum Tragen, das in regelmäßigen Abständen vom Controller auf den Bus geschrieben wird;
        wenn nicht mindestens ein solches {\tt KAL} innerhalb von 0.3s empfangen wurde, sind Klienten dazu angehalten, sich
        selbst in den sicheren Betriebszustand zurückzufahren.

        \subsubsection{Busfreigabe und Client-zu-Controller-Botschaften}
        Da alle vom Controller verwendeten direkten Steuerbefehle Priorität über Client-Befehle haben (mit Ausnahme
        von {\tt ACK} und {\tt SYS}, die von Clients im Rahmen von vom Controller angestoßenen Kommunikationssequenzen
        gesandt werden dürfen, sowie des schweren Systemfehlers {\tt SYS:EGLBL}, der alle Systeme in den sicheren Betriebszustand zwingt),
        muß der Bus vom Controller explizit freigegeben werden. Dies kann alternativ durch das Nicht-Versenden von Nachrichten oder
	dem Versand eines minimal prioritisierten {\tt NOP}-Befehls (zu Debug-Zwecken) geschehen.
	Eine solche explizite Freigabe erfolgt, wenn der Controller selbst keine anstehenden Botschaften hat,
        ansonsten in regelmäßigen Intervallen.


        {\tt RTX}- Übertragung läuft analog zur {\tt STX}-Übertragung von Controller zu Client, verwendet jedoch einen eigenen
        Sequenzzähler\footnote{Die historische Begründung dafür liegt im Wunsch, Vollduplex effizient unterstützen zu können; dies war
        relevant für die Verwendung von LLO über die serielle Schnittstelle.}.\\
        {\tt RTX}-Botschaften sind die einzigen Botschaften die, auf vier Prioritisierungsstufen, noch einmal untereinander an Wichtigkeit
        unterscheiden können. Eine genaue Spezifikation der Verwendung dieser Prioritisierung wurde im Rahmen dieser Studienarbeit nicht
        durchgeführt und den endgültig die Geräte programmierenden Mitentwicklern überlassen.

        \subsection{Umsetzung und Tests}
        Das LLO-Protokoll wurde in C zu Testzwecken, aber auch zur seriellen Kommunikation implementiert. F\"ur den SX-Chip
	wurde aus terminlichen Gr\"unden nur ein vereinfachtes Protokoll mit der vorgesehenen endg\"ultigen API implementiert;
	die vollst\"andige Protokollimplementierung mu\ss te (ebenfalls aus terminlichen Gr\"unden) auf Mitte Mai 2003 verschoben
	werden.

        \subsection{Einsatz im Proxy}
        Zur Kommunikation zwischen PDA und dem Rest des Busses muß ein ``Proxy'' verwendet werden, eine
        dedizierte Platine, die der Vermittlung zwischen CAN-Bus und der seriellen Schnittstelle des PDAs dient.
        Die Kommunikation zwischen Proxy und PDA findet über die serielle Schnittstelle statt, die beide
        Geräte optional auf Vollduplex betreiben können. Hierbei werden LLO/LLZ-Nachrichten vermittels eines
	einfachen seriellen Protokolls (SLP, beschrieben in \ref{slp-proto}) \"ubertragen, das der Trennung
	von Bl\"ocken dient.\\
        Der Proxy selbst nimmt im Netz noch eine weitere Aufgabe wahr: Er Überprüft das Vorhandensein des PDAs
        und sendet einen Broadcast der Form {\tt SYS:EGLBL} im Falle des Ausbleibens von Antworten des PDAs
        (Systemabsturz, Ausfall, oder Entfernung des Gerätes), um im Falle der Ausschaltung der zentralen
        Kontrollinstanz die angeschlossene Peripherie in den sicheren Betriebszustand zu zwingen. Zudem best\"atigt er
	selbst {\tt RTX}-Sendungen mit {\tt ACK}, um die Implementierung von Timeout-Behandlung auf der Peripherie
	unn\"otig zu machen.\\
\newpage

\section{Das LLZ-Protokoll}

Das LLZ-Protokoll ist ein zustandsbasiertes Protokoll, das eine feste Maximallänge von Botschaften vorsieht (16 Bytes, mit einer Minimallänge von einem Byte) und
eine sehr spezifische Semantik erzwingt. Zudem implementiert es den letzten noch fehlenden Aspekt des
Korrektheitskriteriums, die Erkennung der Nichterreichung ihres Ziels durch eine Nachricht\footnote{Die vollständige Protokollspezifikation findet sich als Anhang (Sektion \ref{llz-proto}).}.

        \subsection{Struktur des Protokolls}

        LLZ definiert Kommunikation zwischen genau zwei Teilnehmern, von denen einer dedizierter Sender und der andere Empfänger ist (somit
	\"uberl\"a\ss t es die Handhabung gr\"o\ss erer Mengen von Teilnehmern dem darunterliegenden LLO-Protokoll).
        Beide können Kommunikation initiieren, aber nur der Sender kann eine Antwort ``erzwingen'' lassen; zudem
        ist er auch derjenige, der den Zustand des Empfängers kontrolliert.\\
        Das LLZ-Protokoll wird in mehreren Instanzen verwendet, wobei maximal eine pro Kanal des unterliegenden Protokolles angeboten wird
        (bei LLO werden aufgrund der maximal 30 verwendeten nicht-Controller-\newline Adressen also höchstens 30 Instanzen des Protokolls zugleich ausgeführt).

        \subsubsection{Zustände der LLZ-Empfänger}

        Bevor es jedoch zu einer Ausführung der Datenübertragungen des Protokolles kommt findet die Initialisierung der Busteilnehmer
        statt, bei der der Sender zugleich (möglichst durch Verwendung von Broadcasts eines unterliegenden Protokolles) überprüft,
        wieviele Protokollinstanzen er zu verwenden hat, auf welchen der Kanäle des unterliegenden Protokolles also Empfänger zu erwarten sind.\\

        Clients befinden sich initial im {\tt PRE-INIT}- Zustand, der ihnen jegliche Kommunikation auf dem Bus, mit Ausnahme der Beantwortung
        von Initialisierungssignalen ({\tt INI}) verbietet. Sobald sie ein solches Signal erhalten, gehen sie kurzfristig in einen
        weiteren Zustand ({\tt INIT}), in dem sie eine Überprüfung der Protokollversionsnummer durchführen und, falls kein Fehler auftrat
        (den sie an den Sender kundtun würden, um Sendern, die mehrere Protokollversionen unterstützen, eine entsprechende Suche zu ermöglichen),
        in den {\tt RUNNING}-Zustand über, der ihren normalen Operationsmodus darstellt. Dabei wird ein weiteres Signal an den Sender, {\tt IOK},
        versandt.\\
        Auf Befehl des Senders hin schalten sie sich (eventuell auch schon aus dem {\tt PRE-INIT}-Zustand) in den {\tt DOWN}-Modus, der
        dem sicheren Betriebszustand entspricht.

        \subsubsection{Befehlstabelle}

        Bei der Bestätigung der erfolgreichen Initialisierung vermittels des {\tt IOK}-Blockes wird eine Tabelle der von diesem
        Gerät unterstützten Befehle mitverschickt; diese Tabelle ist bitweise kodiert, wobei in 16 Bytes Raum für 128 Befehle geschaffen wurde.
        Eine spezifische Wahl der Befehlscodes wurde im Rahmen dieser Studienarbeit nur zu Testzwecken durchgeführt und wird späteren
        Implementierern überlassen, um nach genauerer Auswahl der zu verwendenden Peripherie eine Abstimmung deren Priorit\"aten untereinander
	den mit der tats\"achlichen Betriebsweise vertrauteren Entwicklern zu \"uberlassen.\\
        Der Vorteil einer derart versandten Tabelle ist eine eingeschränkte ``Plug-and-Play''- Nachrüstbarkeit der Peripherie, sowie
	die M\"oglichkeit f\"ur
        Treiber seitens des PDAs\footnote{welche ihre Klienten üblicherweise auf einem bestimmten Kommunikationskanal erwarten}, mittels
        der Befehlstabelle unmittelbar die Verfügbarkeit von Funktionen, die in einer echten Teilmenge der Menge der Versionen
        der Peripherie implementiert wurde, überprüfen, und somit ihre Handlungen oder die von ihrer API angebotene Funktionenmenge
        entsprechend ausrichten.
	Zudem erlaubt sie
	eine fr\"uhzeitige PDA-seitige Erkennung nicht erlaubter Befehle; dort ist es leichter, Entwickler \"uber diesen Fehler
	zu informieren\footnote{Ein SX-Assembler-seitiger Pr\"aprozessor zur korrekten Erstellung dieser Befehlstabelle w\"are hier
	  ein n\"utzliches Werkzeug, eine entsprechende Implementierung steht jedoch noch aus, da die SX-Entwicklungsumgebung
	  integriert ist und somit keine einfache Einbildung in einen Buildprozess erlaubt.}.

	\subsubsection{Semantik der Befehle}

	Wie im Protokoll spezifiziert, ist die Semantik der Befehle eine Semantik der {\it absoluten Zustandstransformation}, in
	der f\"ur einen Befehl $p$ mit einem festen Befehlscode und $n$ Parametern gilt, da\ss\ f\"ur beliebige
	$\overline{x} = x_1, \ldots, x_n$, $\overline{x}^\prime = x_1^\prime, \ldots, x_n^\prime$ die Ausf\"uhrung von
	$p(\overline{x})$ nach $p(\overline{x}^\prime)$
	den gleichen internen Zustand wie die
	Ausf\"uhrung von
	$p(\overline{x})$ ohne $p(\overline{x}^\prime)$
	erzeugt. Die Motivation f\"ur diese (die Ausdrucksf\"ahigkeit prinzipiell einschr\"ankende) Designentscheidung ist wie folgt:
	\begin{enumerate}
	  \item{Senderseitig ist es damit m\"oglich, eine konstante Maximalgr\"o\ss e f\"ur die Nachrichtenqueue zu definieren}
	  \item{Das Designprinzip des doppelten Zustandsautomaten wird erzwungen, da alle ``relevanten'' Zust\"ande nun
	    PDA-seitig dupliziert werden. Dies nimmt den Entwicklern Designfreiraum, ohne ihnen Funktionalit\"at vorzuenthalten,
	    was uns aufgrund der Wahl der endg\"ultigen Entwickler sinnvoll erschien.}
	  \item{Im Fehlerfall k\"onnen neuere Botschaften \"altere auch Senderseitig \"uberschreiben und unn\"otigen Neuversand
	    verhindern (nach explizitem \"Ubertragungsabbruch)}
	\end{enumerate}

        \subsubsection{Timeouts}

        Datenübertragungen in LLZ nehmen an, daß sie vollständig und hinreichend korrekt durchgeführt werden oder
        jedenfalls dem Übertragenden eine Nachricht zukommt, wenn bei der
        Übertragung ein nicht korrigierbarer Fehler auftrat (im LLO-Protokoll ist das bei massivsten Datenverlusten
        und fehlschlagender Fehlerbehandlung der Fall). Von der korrekten Überprüfung der Beantwortung von Botschaften
        geht es jedoch nicht aus, daher wird bei jeder Versendung eines Befehls $b$ mit beliebigen Parametern zum
        Zeitpunkt $t$ ein Tupel $(b, t)$ gespeichert, wobei eine (partielle) Zuordnung $\mbox{\it sent}\ b \mapsto t$ resultiert,
        also jedem $b$ ein eindeutiges $t$ (jeweils das aktuellste Datum, da, wie gefordert, gleiche Befehle sich ``gegenseitig überschreiben'')
        zugeordnet ist.\\
        Mit dieser Information wird nun in regelmäßigen Intervallen nach Timeouts von Antworten gesucht und somit der Rest des Korrektheitskriteriums
        erfüllt\footnote{Tatsächlich wird natürlich manchmal umsonst Alarm geschlagen, da unter Umständen nur die Bestätigung verloren gint, aber
        dies haben wir nicht ausgeschlossen}.

        \subsection{Umsetzung und Tests}

        Die Implementierung der Timeouts beschränkt sich auf den PDA; auf der Ebene der SX-Controller, also der Clients,
        ist im Allgemeinen kein ausreichender Speicherplatz für eine Timeout-Fehlerbehandlung; Timeouts treten zudem meist in Situationen auf,
        in denen der Client vom Netz abgetrennt ist, ein Fall, der jedoch bereits durch das periodische Keepalive-Signal
        des LLO-Busses behandelt wird.\\
        Die Implementierung und Anbindung auf Hochsprachenebene wurde abgeschlossen, auf SX-Ebene ist jedoch zum Zeitpunkt des
        Schreibens nur ein Fragment der Implementierung verfügbar.\\
        In der ersten Implementierung ist die Beschränkung von Befehlen zumindest SX-seitig auf solche mit bis zu 5 Bytes an Parametern
        vorgesehen; Notifikationen ({\tt NTF}) und Kommandos ohne Antworten ({\tt CMD})  werden nicht verwendet werden.


\newpage

\section{Fazit}

Im Rahmen des Projektes wurde eine für die Zwecke des Läufers geeignete Kommunikationsstruktur entworfen und getestet, eine
vollständige Implementierung auch auf den Mikrocontrollern war aus verschiedenen Gründen bis zur Fertigstellung dieser Ausfertigung
nicht mehr möglich und muß im Anschluß erfolgen. Zum Ausgleich wird anstelle von LLZ zur Zeit ein vereinfachtes Protokoll (MLP, ebenfalls
eine Eigenentwicklung) eingesetzt. Die endg\"ultige Entwicklung wird nach Abschlu\ss\ der M.Sc. Thesis des verantwortlichen Entwicklers
nachgereicht.


\section{Ausblick}
In zuk\"unftiger Arbeit planen wir, die  Implementierung des LLZ-Protokolles abzuschlie\ss en. Danach hoffen wir, eine vereinfachte Programmierunmgebung
f\"ur das synchrone Zustandsmodell entwerfen und implementieren zu k\"onnen sowie eine Kaskadierung des LLZ-Protokolles zur
Vergr\"o\ss erung des Adressraumes zu spezifizieren und, bei Bedarf, zu implementieren. Parallel dazu planen wir Benchmarks, um den
hinreichenden Durchsatz unserer Implementierung zu demonstrieren.


