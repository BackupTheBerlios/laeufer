% TODO: Fazit, Einleitung

\section{Einleitung}

Der Läufer ist kein Monolith. Nicht nur kann das wendige Fahrzeug kaum mit einem statischen Felsbrocken
verglichen werden, sondern auch-- und insbesondere-- ist sein Aufbau modular. Doch die Module schweben, wie
das im Reich der Hard- und Software nun einmal Sitte ist, nicht in isolierten Welten; Kommunikation,
Datenübertragung zwischen ihnen ist essenziell, denn Blinker und Scheibenwischer können nicht, oder jedenfalls
bestenfalls in beschränktem Umfang, über ihre Zustände entscheiden, und zugleich kann und will man diese einzelnen
Elemente nicht unmittelbar mit dem Fahrer verdrahten, der bei der Fahrt meist besseres zu tun hat, als Blinker
über DIP-Schalter zu konfigurieren.


Dieser Abschnitt widmet der Kommunikation zwischen den Elementen des Läufers, insbesondere zwischen der zentralen
Steuereinheit, hier durch einen PDA realisiert, und ihren Klienten. Verschiedene Möglichkeiten der Konstruktion
eines Datenübertragungssysteme werden beschrieben und bewertet werden, mit einer abschließenden Beschreibung der ge-wählten
Kommunikationsinfrastruktur.


\section{Vorüberlegung}

Bevor wir uns in die faszinierende Welt der Datenübertragung stürzen, sollten wir, jedenfalls
für dieses spezielle Projekt, eine Grundsatzentscheidung treffen: Wollen wir ein möglich
zentral gesteuertes Netzwerk verwenden, in dem das Maximum an Entscheidungen vom PDA
getroffen wird, oder diese Entscheidungen, soweit möglich, den zu verwenden vorgesehenen SX-Platinen überlassen?


Ein Vorteil einer zentralistisch angelegten Steuerung scheint, jedenfalls bei einem Reisefahrzeug,
nur schwer erkennbar; der übliche Grund für solche Konstruktionen, die Minimierung von Redundanzen, greift
in einem Netz von konzeptionell ohnehin separaten Einheiten nicht. Somit sollten wir, um den
Datenübertragungsaufwand zu minimieren, nur mehr Konfigurationsinformationen vom PDA an die Peripherie,
und umgekehrt nur wirklich auf dem PDA notwendige Informationen versenden; letztere lassen sich zusammenfassend
als für den Fahrer gedachte Angaben-- Geschwindigkeit, Akkumulatorstand-- und zur Weiterleitung an andere
Geräte vorgesehene Informationen wie Zustände von als Peripherie angeschlossenen Lichtschaltern oder Blinker-Hebeln
beschreiben\footnote{Das Vorkommen der letztgenannten Informationen ist nicht zwingend erforderlich, falls
die Peripherie unmittelbar miteinander kommunizieren kann, z.B. durch eine Direktverbindung oder in einem
Multi-Master-Bussysstem.}.

\newpage

\section{Anforderungen an die Kommunikation}

Kommunikation, wenn nicht Selbstzweck-- wie bei allen Dingen-- muß an der Meßlatte
dessen beurteilt werden, was ihr Ziel und Zweck ist. Um von einer ``guten'' oder ``schlechten''
Lösung unsres Kommunikationsproblemes sprechen zu können, stellt sich uns somit zunächst die Aufgabe,
die zur Bemessung der gesuchten Qualität dienenden Kriterien niederzuschreiben und auszuformulieren,
nicht zuletzt gegeneinander abzuwägen, denn eine vollständige Ordnung muß sein, jedenfalls für ein
eindeutiges Urteil.

Das diese Abwägung nicht einfach sein muß, ist einleuchtend, doch führen wir sie trotz dieser
Vorüberlegung zunächst aus, um eine Beurteilungsbasis zu bilden. Was also sind jene Meßlatten,
die wir unsrer Kommunikationslösung anlegen wollen?

	\subsection{Korrektheit}

	Alle übertragenen Daten müssen korrekt sein.


	Zu diesem Punkt muß mehr gesagt werden, als sein Name hergibt. Korrektheit findet sich auf mehrere
	Arten und Weisen in unseren Forderungen wieder, die wir hier, milde axiomatisiert, auflisten wollen:

	\begin{enumerate}
	  \item{Wenn ein Datum den Empfänger nicht erreicht, muß der Sender davon erfahren}\label{j-correct-0}
	  \item{Wenn ein Datum den Empfänger erreicht, muß es zuvor versandt worden sein}\label{j-correct-1}
	  \item{Wenn ein Datum den Empfänger mehrfach erreicht, muß seine Semantik idempotent sein}\label{j-correct-2}
	\end{enumerate}

	Von diesen drei Forderungen ist insbesondere die Nummer \ref{j-correct-2} erläuterungsbedürftig. In Kommunikationssystemen
	kommt es erfahrungsgemäß vor, daß versandte Pakete aufgrund von unangemessen ausgelösten Fehlerbehandlungen (üblicherweise,
	wenn die Bestätigung der Gegenseite einem unbemerkten Übertragunsfehler zum Opfer fiel) wiederholt versandt werden.
	Unsre obige Forderung ist nun auf zwei Weisen erfüllbar, nämlich zum Einen, indem verhindert wird, daß
	der Empfänger die Botschaft mehrfach erhält, oder zum Anderen, indem auf einer höhergelegenen Interpretationsebene (auf die
	somit diese Fehlerbehandlung verschoben wird) der Doppelempfang ohne Folgen bleibt.

	Die erste Forderung ist in der Praxis auf eine sehr hohe Protokollebene verschiebbar, insbesondere, da wir Bidirektionalität fordern, ihr
	wesentlicher Vorteil, die Erkennung einer Situation, in der ein bestimmtes Gerät vom Netz abgetrennt wurde, jedoch in
	genau dieser Situation für dessen bedürfende Geräte durch erzwungene Antworten auf alle an den Empfänger gerichteten
	Anfragen erreicht werden kann.

	Diese drei Implikationen werden unsre Grundforderungen bilden. Da wir jedoch jenseits der Wunderbaren Welt der
	theoretischen Informatik operieren, werden sie natürlich nur ``in den allermeisten Fällen'' erfüllbar sein,
	aber diese Aussage bezieht sich natürlich auf alle unsre Forderungen. Diese speziellen Forderungen jedoch sind von der
	Art, in der sich wenig Verhandlungsspielraum-- im Gegensatz, zum Beispiel, zur Übertragungs-geschwindigkeit-- ergibt, somit
	müssen wir bei von uns gewählten Technologien stets auf ihre Erfüllung oder Erfüllbarkeit achten.

	\subsubsection{Bedeutung der Forderungen}

	Die Forderungen selbst sind übrigens durch ein triviales Modell bereits erfüllbar, einen {\it wissentlichen Nichtverschicker},
	der kein Datum versendet und den Sender davon in Kenntnis setzt (was die erste Forderung unmittelbar und die beiden anderen
	trivial erfüllt). Die Forderung, daß überhaupt Daten übertragen werden können, müssen wir somit auch ausdrük-ken.

	%

	\subsection{Hinreichende Datenübertragungsrate}

	Die Geschwindigkeit, mit der Daten übertragen werden, muß den Anforderungen des Projektes genügen.


	Diese Anforderung ist, in einer derartigen Formulierung, von kaum zu übertreffender Ungenauigkeit, doch eine
	präzise Formulierung der be-nötigten Datenübertragungsrate scheint in der gegebenen Situation kaum möglich, insbesondere,
	da die Menge der anzuschließenden Geräte nicht fest gegeben ist und somit nur eine Abschätzung gemacht werden kann,
	wieviel diese dann schließlich an ``laufenden'' Informationen benötigen beziehungsweise versenden.

	Unsre Vorüberlegung jedoch, den Geräten größtmögliche Autonomie zu gewähren, legt nahe, daß die Bandbreite überschaubar
	bleiben kann; betrachten wir dazu einen typischen Extremfall:

	\subsubsection{Schnelles Tachyometer}

	Typische Geschwindigkeitsmesser in verwandten Fahrzeugen werden oft nicht häufiger als zwei Mal pro Sekunde mit neuen
	Informationen versorgt; ein genauer auflösendes Tachyometer könnte zum Beispiel mit der Fernseh-typischen Rate von 25 Hz eine
	als ständig aktuell erscheinendende Qualität erreichen; bei 24 Bit Datenlast (8 Bit Kennziffer, 16 Bit Information)
	wären dies folglich, in diesem Beispiel, 600 bps für dieses eine Gerät.


	Auf die nächsthöhere glatte Zahl aufgerundet (um eventuellen Un-wägsamkeiten, wie Datenverlust, zumindest in einem bescheidenen Maße
	vorzubeugen) wären dies 1024, für eine geschätzte Obergrenze von 16 Geräten also
	16384 bps im auf Datenlast eingeschränkten Übertragungs-verkehr-- also Kontrolldaten ignorierend-- als theoretisches Minimum.
	Das ist, aus heutiger Sicht, nicht sehr viel, was aber, nach der Vorüberlegung, unsren Erwartungen grob entspricht.


	Bandbreite alleine reicht natürlich nicht unbedingt; die Erzählung vom mit CD-ROMs beladenen Güterzug als König der Bandbreite ist
	geläufig genug, um an eine andere häufige Forderung der Datenübertragung zu erinnern.

	%

	\subsection{Geringe Latenzzeiten}

	Die Zeit, die zwischen dem Versand und dem Eintreffen eines Datenpaketes vergeht, sollte minimal sein.


	Erneut eine eher vage Forderung, die an unsere Argumentation zur nicht-Zentralisiertheit erinnert. Wie 'minimal' die Verzögerung sein
	sollte, ist an praktischen Beispielen wohl-- abgesehen von offensichtlichen Beschränkungen-- am ehesten an einer doppelten
	Übertragung zwischen einem Schalter und einer anderen Peripherie, beispielsweise einem Scheinwerfer, erkennbar; hier machen sich
	hohe Latenzzeiten zwar nicht in einer gefährdenden, aber doch für den Fahrer ersichtlichen und irritierenden Weise
	bemerkbar. Bei einer nicht direkten Verdrahtung müßte also eine Übertragung zweier Botschaften innerhalb kurzer
	Zeit versandt werden können, bei
	direkter Kommunikationsmöglichkeit zwischen Schalter und Licht verringert sich dies auf eine einzelne Botschaft.

	Eine gute Latenzzeit für diesen Kommunikationsschritt wäre, wie im letzten Kriterium erwähnt, 0.04s; praktisch ausreichend
	wäre jedoch auch eine schlechtere Zeit von 0.1s, da, wie erwähnt, zu guter Letzt doch ``nur'' wieder das Empfinden des Fahrers bedient wird.

	Gerade an diesem Beispiel sieht man natürlich eine zuvor schon oft implizit erwähnte notwendige Anforderung, die als nächstes ausgeführt werden soll.

	%

	\subsection{Bidirektionalität}

	Kommunikation zwischen Peripherie und PDA sollte in beide Richtungen möglich sein.


	Diese Forderung ergibt sich unmittelbar aus der Notwendigkeit, Informationen, wie, zum Beispiel, die aktuelle Reisegeschwindigkeit,
	aus Peripheriegeräten auszulesen.

	%

	\subsection{Unterstützung für mehr als einen Client}

	Es sollte möglich sein, mehr als ein Peripheriegerät mit dem PDA kommunizieren zu lassen.


	Ähnlich wie beim vorherigen Punkt, der Bidirektionalität, ergibt sich diese Notwendigkeit aus praktischen Erwägungen. Eine
	Ermangelung an Bidirektionalität oder Mehr-Client-Funktionalität wäre zwar allgemein\\durch Verwendung mehrerer paralleler
	Kommunikationssysteme aus-\\gleichbar, eine solche Konstruktion ist aufgrund des Mehraufwandes an Hardware und der grundsätzlich
	anderen Ansteuerung jedoch separat zu handhaben. Die angeklungene Forderung nach einem eher geringen Hard-ware-Aufwand läßt sich
	im Übrigen noch verallgemeinern, wie wir im nächsten Punkt sehen werden.
	%

	\subsection{Geringe Ressourcenanforderungen}

	Das verwendete Kommunikationssystem soll ``möglichst wenig'' Hardware, Strom, und Prozessorleistung der beteiligten Kommunikationssysteme
	benötigen.



	Eine präzisere Angabe jenseits von offensichtlichen Schranken des\\ Machbaren sind hier nicht möglich; dies ist ein eher komparatives Kriterium.

	%

	\subsection{Praktische Realisierbarkeit mit gegebenen Mitteln}

	Das Kommunikationssystem muß an finanziellem und technischem Aufwand realistisch implementierbar sein.


	Insbesondere ist, rein komparativ gesehen, eine Unterstützung seitens der Sponsoren, sowohl materiell als auch
	mit Informationen und praktischer Unterstützung ein relevantes und jedenfalls im Zweifelsfall den Ausschlag gebendes Kriterium.
	%


	\subsection{Die Minimalanforderungen}\label{j-min-req}

	Um nun nicht unnötig auszuschließen, wollen wir unsre Minimalforderungen derart formulieren, daß der Ausgleich fehlender
	Eigenschaften auf einer höheren Ebene prinzipiell erlaubt sein soll, endgültiger Ausschluß einer Technologie würde also nur
	erfolgen, wenn sie das Erfüllen eines der Kriterien (in einem angemessenen Maß) prinzipiell ausschließen würde.

	Wir fordern von gewählten Technologien minimal, daß sie nicht ausschließen, daß folgende Kriterien erfüllt werden:
	\begin{enumerate}
	  \item{\bf Korrektheit}
	  \item{{\bf Hinreichende Datenübertragungsrate}: Mindestens 16384 bps für\\ Daten alleine}
	  \item{{\bf Geringe Latenzzeit}: Maximal 0.05s pro Botschaft oder 0.1s für zwei Botschaften\footnote{Diese beiden Kriterien sind sehr unterschiedlich, da z.B. über Priorisierungsmechanismen unter Umständen sichergestellt werden kann, daß Botschaften, die eingingen, jedoch weiterversandt werden müssen, eine geringere Latenzzeit haben. Auf der anderen Seite jedoch ist es-- bei einer Latenz von konstant 0.05s-- durch zusätzlichen Bearbeitungsaufwand möglich, daß dennoch ein wenig mehr als 0.1s benötigt wird. Diese Zeit betrachten wir jedoch als unerheblich und verwenden somit 0.05s als ein einfacher zu handhabendes Kriterium.}}
	  \item{\bf Bidirektionalität}
	  \item{\bf Unterstützung für mindestens 16 Peripheriegeräte}
	  \item{{\bf Geringe Ressourcenanforderungen}: Strombedarf auf Platine abdeckbar, eventuelle Kabel maximal handelsübliche Koaxialkabel an Dicke, 
	    sonstige Hardware sollte maximal soviel Masse haben wie der Rest der SX-Platine}
	  \item{\bf Praktische Realisierbarkeit}
	\end{enumerate}


	Mit diesen sieben Kriterien werden wir nun die verschiedenen Möglichkeiten, die sich uns zur Kommunikation bieten,
	beurteilen.

\newpage

\section{Alternativen der Kommunikationshardware}

Wir werden nun eine Reihe von Alternativen durchgehen, die uns, verbunden mit verschiedenen Vor- und Nachteilen,
Kommunikation zwischen PDA und Peripherie erlauben. Im Falle einiger dieser Technologien könnten die benötigten Anschlüsse
zwar unmittelbar auf die SX-Board aufgelötet werden, eine Kommunikation mit dem PDA würde jedoch einer Zwischenstation, eines
Proxys, benötigen. Da auf den genannten Platinen ohnehin ein serieller Anschluß vorhanden ist, können sie, bei
entsprechender Programmierung, unmittelbar als ein solcher dienen (sofern die verwendete Kommunikationsmethode
der Forderung nach {\bf Bidirektionalität} genügt).\\

	\subsection{Einfache Hartverdrahtung}
	
	Die einfachsten Dinge sind oft auch die besten, daher wollen wir zunächst die Direktverbindung des PDAs mit der Peripherie über direkte
	Kabelverbindungen betrachten.

	Diese Lösung erfüllt zunächst unsre Minimalanforderungen, erlaubt beliebig viele Peripheriegeräte und ist an Bandbreite und Latenz nur durch
	den Systembus des SX-Controllers begrenzt. Doch schon hier stellt sich die erste Frage: Wie verbindet man die Controller direkt an ihrem
	Systembus? Ein Arbitrierungsmechanismus müßte herbei, es muß sichergestellt werden, daß keine Übertragungen verloren
	gehen\footnote{Erste Forderung der Korrektheit}. Aber
	damit haben wir schon wesentlich mehr als eine einfache Hartverdrahtung; wenn wir jedoch unser Modell beibehalten wollen, bliebe uns nur,
	die Peripherie direkt mit den Eingängen der SX-Ports zu verbinden. Dies würde natürlich die Anzahl der anschließbaren Peripheriegeräte unmittelbar
	beschränken-- die notwendigen 16 Geräte sollten jedoch kein prinzipielles Problem darstellen.

	Eine direkte Verbindung erzwingt jedoch einen unnötig komplexen Kabelbaum (wenn zwei Peripheriegeräte direkt
	nebeneinander liegen, ist es nicht ausreichend, sie miteinander zu verbinden-- jedes von ihnen muß einzeln verkabelt sein). Eine derartige
	Konstruktion würde Masse am Läu-fer kosten und wäre fehleranfällig; dennoch verbleibt die Hartverdrahtung als eine, wenn auch nicht
	optimale, Möglichkeit. Ihr Hauptvorteil, die hohe Geschwindigkeit und geringe Latenz (die durch zwischengeschaltete Verstärker
	jedoch geringfügig leiden dürfte) ist im Projektrahmen zwar interessant, aber nicht fundamental ausschlaggebend.
	
	%

	\subsection{Drahtlose Kommunikation}

	Die Zusammenfassung aller drahtlosen Kommunikationsmittel in einer einzigen Sektion legt das Urteil über diese natürlich bereits nahe,
	daher will ich es ohne Umschweife ausformulieren.

	Drahtlose Kommunikation benötigt mehr Leistung als hartverdrahtete Kommunikation und ist störungsanfälliger; da sie kein geschlossenes
	System erlaubt (jedenfalls nicht ohne harte Kryptographie, die jenseits der Schranken der praktischen Realisierbarkeit lag), ist
	somit auch die Erfüllung der Forderungen der Korrektheit nur schwerlich vorstellbar.
	%

%	\subsection{Universal Serial Bus (USB)}
	%
%% -- fixme -- %%

%	\subsection{IEEE 802}
	%
%% -- fixme -- %%

%	\subsection{IEEE 1394 ,,Firewire''}
	%
%% -- fixme -- %%

%	\subsection{Profibus}
	%
%% -- fixme -- %%

%	\subsection{InterBus}
	%
%% -- fixme -- %%

	\subsection{Actuator Sensor Interface (AS-i)}
	Das 1993 entworfene Actuator Sensor Interface des AS-i Konsortiums
	ist ein Master-Slave-System mit bis zu 31 Slaves, das sich insbesondere
	durch eine sehr geringe Komplexität auszeichnet. Tatsächlich erfüllt
	es alle Anforderungen, die von uns an ein solches Netzwerk gestellt werden;
	sein einziger wesentlicher Nachteil ist die Beschränkung der Größe des Ein- und
	Ausgangskanals auf je 4 Bit, was zu einer Verwendung von fragmentierter
	Datenübertragung zwingt.\\
	Da wir jedoch zu spät von seiner Existenz erfuhren und nicht unmittelbar
	mit Unterstützung seitens der Sponsoren rechnen konnten, muß seine
	Bedeutung auf eine Aufführung in dieser Ausarbeitung beschränkt bleiben.
	%
%% -- fixme -- %%

	\subsection{Controller Area Network (CAN)}

	Das Controller Area Network, 1986 von der Robert Bosch AG zur
	Multi-Master-Kommunikation im Auftrag von Mercedes entwickelt,
	erfreut sich heutzutage einer wachsenden Beliebtheit auch bei
	anderen KFZ-Her-\\stellern wie BMW, Porsche, Fiat etc., wird
	jedoch auch außerhalb der Automobilbranche genutzt.


	Das CAN-Protokoll ist ein reines Kommunikationsprotokoll
	(welches auch vielfach bereits in Hardware implementiert
	wurde), bezieht sich also nicht auf die	verwendeten
	physikalischen Transfermedien und die darübergelegene
	``Objektschicht'' (wie die darüberliegenden Schichten
	gem. OSI-Modell von der CAN-Spezifikation genannt
	werden). Zur Zeit existieren zwei relevante, im gleichen Netz
	ineroperable Protokollversionen:

	\subsubsection{CAN 1.2}
	Version 1.2 des Protokolls stellt Mechanismen zur
	Bus-Arbitrierung, Erkennung und Korrektur fehlerhafter
	Datenübertragungen und einen vorgesehenen Adressraum von 11 Bits
	für angeschlossene Geräte zur Ver-fügung; aufgrund einer
	protokollbedingten Einschränkung ist jedoch ``nur''
	eine Adressierung von 2032 Busteilnehmern möglich.\\
	Ein zur unmittelbaren Datenübertragung verwendetes CAN-Frame
	(der Version 1.2) maximaler Größe beinhaltet 8 Bytes an Daten
	und belegt (inkl. Inter-frame space, dem Abstand zweier
	Frames) 111 Bit.\\
	Das Protokoll selbst läßt die genaue Hardware-Implementierung
	offen, gängig sind jedoch Raten von 1 Mb/s bei minimalem
	Verdrahtungsaufwand, was unsere Minimalanforderungen mehr als
	abdeckt.


	\subsubsection{CAN 2.0}
	Diese Protokollversion unterscheidet sich von CAN 1.2
	lediglich in der optionalen Verfügbarkeit von
	29-Bit-Bezeichnern\footnote{Die Einführung dieser Erweiterung
	begründet sich historisch aus von der American Society of
	Automative Engineers (SAE) gestellten Anforderungen}.

	%

	\subsection{Vehicle Area Network (VAN)}

	Dieses Netzwerk, in direkter Konkurrenz zum CAN, wurde in Frankreich entwickelt, scheint sich jedoch keiner vergleichbaren
	Popularität zu erfreuen. Ebenfalls als Multi-Master-fähiges
	Protokoll entworfen, wurde es 1994 ISO-standardisiert, hat
	jedoch keine (uns relevant erscheinenden) markanten Vorteile
	gegenüber seinem Konkurrenten.

	%

%	\subsection{Konklusion}

%% -- fixme -- %%
\newpage

\section{Übrige Anforderungen und Umsetzung}
	\subsection{Bereits durch CAN abgedeckte Anforderungen}
	Untersuchen wir nun die gestellten Anforderungen in Bezug auf bereits
	stattgefunden habende Abdeckung durch CAN selbst:

	\begin{enumerate}
	  \item{{\bf Korrektheit}: Wir erinnern uns an die drei geforderten Eigenschaften:
	    \begin{enumerate}
	    \item{{\it Wenn ein Datum den Empfänger nicht erreicht, muß der Sender davon erfahren}:
	      Diese Implikation wird von CAN nicht selbst erfüllt; ein erweiterndes Protokoll müßte
	      sie sich zur Aufgabe setzen. In unmittelbarem Zusammenhang damit ergibt sich ein praktisch
	      relevantes Problem: Kurzzeitige Leitunsstörungen können den Verlust einzelner Botschaften zur
	      Folge haben, ohne, daß die Kommunkation unbedingt zusammengebrochen wäre. Diese Situation
	      erfordert Neuversendungen der alten Daten, wird jedoch nicht von CAN abgedeckt, da dieses
	      Protokoll keine empfangenen Sendungen quittiert.
	    }
	    \item{{\it Wenn ein Datum den Empfänger erreicht, muß es zuvor versandt worden sein}:
	      Wird trivial von CAN erfüllt.}
	    \item{{\it Wenn ein Datum den Empfänger mehrfach erreicht, muß seine Semantik idempotent sein}:
	      Die Prämisse gilt in CAN nicht, somit muß die Konklusion nicht erfüllt werden.}
	    \end{enumerate}
	  }
	  \item{{\bf Hinreichende Transferrate}: Marktübliche Implementierungen liefern 1 Mb/s; bei Wahl eines hinreichend
	    intelligenten Protokolles sollte die gewünschte Mindest-Transferrate somit zu erreichen sein:
	    Eine solche Basis-Übertragungsrate liefert,
	    bei zwischen 111 ($1 \times 8$) und 440 ($8 \times 1$) Bits
	    für 8 Byte, also zwischen knapp 580000 und 145000 bps alleine für
	    Daten \footnote{falls keine Fehlerbehandlung nötig ist}, weit mehr,
	    als gefordert.
	  }
	  \item{{\bf Geringe Latenzzeiten}:
	    Die Latenzen in CAN sind, wie allgemein in Bus-Systemen üblich, minimal. Bei 111 für schlechtest
	    mögliche Frames liegt die Latenz unter 0.00012s, was darüberliegenden Protokollen viel
	    Freiraum einräumt.
	  }

	  \item{{\bf Bidirektionalität}:
	    CAN bietet, als Multi-Master-System, verschiedenste Möglichkeiten multidirektionaler Kommunikation.
	  }

	  \item{{\bf Unterstützung mehr als eines Clients}: Wie angedeutet, sieht CAN 1.2 eine Adressierung von bis zu 2032 Clients vor;
	    tatsächlich könnte durch spätere Auswahl auf den Empfangenen Daten diese Menge beliebig erweitert werden
	    (was im Rahmen dieses Projektes jedoch einer Begründbarkeit entbehren würde).}

	  \item{{\bf Geringe Ressourcenanforderungen}: Die aufgeführten Bedingungen (Subesektion \ref{j-min-req}) werden von der handelsüblichen Hardware
	    uneingeschränkt erfüllt.
	  }

	  \item{{\bf Praktische Realisierbarkeit}: Bei Verwendung dieser Technologie erhielten wir Unterstützung durch unsre
	    Sponsoren (von denen sogar eine entsprechende Empfehlung ausgesprochen worden war).
	  }
	\end{enumerate}

	\subsection{Verbleibende Anforderungen}
	Die wesentliche verbleibende Anforderung ist somit die erste Forderung der Korrektheit, die eine Notifikation
	des Senders im Falle einer fehlgeschlagenen Übertragung voraussetzt. Bevor wir uns über die Bedeutung dieser Forderung
	klar werden


\newpage

\section{Alternativen für das Kommunikationsprotokoll}

Die Wahl des Bus-Systems (für das wir, auf externe Empfehlung hin, CAN-Controller vom Typ
MCP2510 der Firma Microchip Technology Inc.
verwenden), war somit gefallen. Diese liefern die bereits zuvor für diverse Abschätzungen verwendete Übertragungsrate
von 1 Mb/s.

%KILLME%
Offen stand jedoch noch das zu verwendende Datenprotokoll; verbreitete Protokolle sind, insbesondere in Europa,
das CANopen-Protokoll, wobei auch DeviceNet und das Smart Distributed System (SDS) sicher Optionen gewesen wären,
sich jedoch hierzulande durch ihre Verwendung keine unmittelbaren Vorteile ergeben hätten. CANopen jedoch, zu dem
unter Umständen bereits fertige Komponenten verfügbar gewesen wären, wenn auch deren Verwendbarkeit aufgrund der
besonderen Konstruktion des Läufers zweifelhaft erscheinen würde, ist ein sehr komplexes Protokoll, dessen
Implementierung, gerade auch, da die sich ergebenden Vorteile in ihrem Nutzen bestenfalls beschränkt wären,
unnötigen Aufwand ohne nennenswerten Lerneffekt verursacht hätte.


%	\subsection{CANopen}
%% -- fixme: Mention it at the very least -- %%


%	\subsection{DeviceNet}
%% -- fixme: Mention it at the very least -- %%

%	\subsection{Smart Distributed System (SDS)}
%% -- fixme: Mention it at the very least -- %%


	\subsection{Eigenentwicklung}
%	Zuletzt blieb nun noch die Möglichkeit einer auf die Bedürfnisse des Läufers zugeschnittenen Eigenlösung.
%KILLME:
	Daher schien uns die Möglichkeit einer auf die Bedürfnisse des Läufers zugeschnittenen Eigenlösung als die Vielversprechendste.
%STOP KILLING ME

	Diese
	hatte zwar zunächst den unmittelbaren Nachteil, noch nicht entworfen worden zu sein, in Anbetracht der Nicht-
	verfügbarkeit existierender Implementierungen der andren genannten Protokolle für diese Plattform jedoch andererseits
	den Vorteil, mit moderaten Entwurfsaufwand den Implementierungsaufwand den Bedürfnissen des Läufers gegenüber angemessen
	gestaltbar zu sein.

	\subsection{Fazit}
	Schlußendlich fiel unsre Entscheidung schon sehr früh auf eine eigene Entwicklung, da der Aufwand für eine vollständige
	Implementierung bereits existierender Protokolle (soweit ihre Spezifikationen überhaupt öffentlich verfügbar waren) unseres
	Ermessens nach wesentlich höher gewesen wäre, wohingegen die Einschränkung eines dieser Protokolle keine
	merklichen Vorteile gegenüber einem solchen eignen Protokoll erwirkt hätte. 


\newpage

\section{Das Läufer-Protokoll für den CAN-Bus} 

Die Aufgaben des resultierenden Protokolls lassen sich nun wieder auf die bereits zuvor verwendeten Protokollkriterien zurückführen.
Hierbei muß jedoch darauf geachtet werden, die Eigenheiten des CAN-Protokolls zu beachten; die Protokolle haben also nicht nur zur
Aufgabe, unsere Korrektheitsforderungen zu erfüllen, sondern auch, eine gute Anbindung an CAN zu bieten-- wobei es sich von diesem
natürlich aus Gründen eines klaren Designs zumindest in seiner Spezifikation hinreichend weit abtrennen sollte.\\

Unsere Entscheidung fiel zugunsten eines zweischichtigen Protokolldesigns, in dem eines der Protokolle die grundsätzliche Kommunikation und das
andere einfaches Session-Management mit Timeouts spezifizierte. Die Trennung dieser beiden Dinge schien uns in Hinsicht auf die
bevorstehende Implementierung, aber auch aus Sicht der Modularität
sinnvoll.\\

Eine zunächst noch offene Frage war jedoch die Form der Protokolle,
gerade auch, da CAN Unterstützung für Multi-Mastering bietet. Es wurde nun
zunächst der Entschluß gefaßt, das Session-Protokoll für eine
Master-Slave-Kommunikation auszulegen, da dies der angestrebten unmittelbaren
Kontrolle der Peripherie durch ein zentrales System entsprach; dies
erweiterten wir später um einen Notifikationsmechanismus in die andere
Richtung und bauten es somit zu einem zwei-Master-Netz aus.
Das Netzwerk-Protokoll hingegen, das auch die Aufgabe der
Adressierung bestimmter Clients übernehmen sollte, bildete ein
Multi-Master-System mit prioritisierten Botschaften (speziell unter Ausnutzung
der Eigenschaften des CAN-Busses), aus den gleichen Gründen.\\

Aus theoretischer Sicht ist das Netz somit von sternförmiger
Topologie, die tatsächliche Verdrahtung hingegen kann natürlich
beliebig im Rahmen des von CAN Ermöglichten erfolgen.

	\subsection{Die beiden Protokollschichten}
	Die beiden Protokolle, mit Namen {\it LLO} und {\it LLZ} (``Läufer Layer One'' bzw. ``Zero''), nehmen also
	zueinander signifikant andere Aufgaben wahr:

		\subsubsection{Aufgaben des LLO-Protokolls}
		Die Aufgaben des LLO-Protokolls umfassen die folgenden:
		\begin{enumerate}
		  \item{Adressierung der Klienten}
		  \item{Verpackung der zu übertragenden Daten in Pakete des Data Link/ Network Layer (speziell CAN)}
		  \item{Busmastering}
		\end{enumerate}


		\subsubsection{Aufgaben des LLZ-Protokolls}
		Das LLZ-Protokoll übernimmt folgende Teilaufgaben:
		\begin{enumerate}
		  \item{Session-Management}
		  \item{Erfüllung des ersten Korrektheitskriteriums}
		\end{enumerate}
		Eine ``Sitzung'' im für uns relevanten Sinn erstreckt sich hierbei von Aktivierung bis Deaktivierung
		des Läufers.

		\subsubsection{Der sichere Betriebszustand}
		Beiden Protokollen ist ein Konzept zu Eigen, das den Namen ``sicherer Betriebszustand'' trägt, sich
		auf Klienten im Bus bezieht und
		individuell für jedes angeschlossene Gerät definiert werden muß. Dieser sichere Betriebszustand
		ist von angeschlossenen Geräten im Fehlerfall einzunehmen, insbesondere, wenn die Kommunikation nach
		außen abreißt.
\newpage

\section{Der Bezug zum OSI-Schichtenmodell}
Als kurzer Einschub soll hier noch einmal auf das OSI-Schichtenmodell
eingegangen werden, das zwar keinen leitenden Einfluß auf das Protokolldesign
hatte, wohl aber zur nachträglichen Klassifizierung verwendet werden kann.\\
In dem verwendeten Kommunikationssystem werden die Ebenen wie folgt belegt:

\begin{itemize}
  \item {{\bf Schicht 1: Physical Layer}: Diese Schicht findet sich in Verdrahtung, dem MCP2510, dem SX-Microcontroller, und den
    dazwischenliegenden Verbindungen.}
  \item {{\bf Schicht 2: Data Link Layer}: Die Fehlererkennung dieser Schicht ist im CAN-Protokoll spezifiziert, findet sich ent-
    sprechend physikalisch auf dem MCP2510.}
  \item {{\bf Schicht 3: Network Layer}: Ansteuerung der Komponenten wird, im Rahmen der CAN-spezifizierten Vorgaben, von einem
    von einer Implementierung des LLO-Protokolls realisiert. Die wesentliche Arbeit dabei wird durch Filtermechanismen im MCP2510
    realisiert.}
  \item {{\bf Schicht 4: Transport Layer}: Die Zerteilung in einzelne Pakete führt die LLO-Implementierung durch.}
  \item {{\bf Schicht 5: Session Layer}: Die Registrierung von Busteilnehmern und Timeout-Checks bei der Kommunikation werden
    von LLZ realisiert.}
  \item {{\bf Schicht 6: Presentation Layer}: Nach- bzw. Vorbearbeitung der übersandten Daten wird von Geräten und Treibern
    individuell gelöst und ist nicht Teil der hier beschriebenen Kommunikationsschicht.}
  \item {{\bf Schicht 7: Application Layer}: Die tatsächliche Durchreichung der Informationen an den Anwender, ihre optische
    Aufbereitung, automatische Beantwortung oder, allgemeiner, Versendung, findet sich in den anderen Teilen dieser Ausarbeitung
    beschrieben.}
\end{itemize}
    

\newpage

\section{Das LLO-Protokoll}\footnote{Die vollständige Protokollspezifikation findet sich als Anhang (Sektion {\ref{llo-proto}}).}
Das Protokoll geht davon aus, dass versandte Daten ``ganz oder gar nicht'' ankommen, gemäß unsren Korrektheitsforderungen
(die ja zu zwei Dritteln schon von CAN erfüllt wurden). In diesem Rahmen stellt es zusätzliche Sicherheitsmechanismen
und ein Multi-Master-Protokoll, das sich auf CAN implementieren läßt.

	\subsection{Struktur des Protokolls}

	Das LLO-Protokoll ist ein prinzipiell multi-Masterfähiges Protokoll, das die Nutzung der Möglichkeiten von Multi-Master-
	Sendungen jedoch auf asynchrone Notifikationen einschränkt. Somit existiert ein tatsächlicher Master in diesem Netzwerk,
	der als Controller bezeichnet wird; er erhält zugleich eine der 32 im Bus verfügbaren Adressen (1) fest zugewiesen.
	Eine weitere Adresse ist für explizite Broadcasts (z.B. für eine totale Systemabschaltung im Falle der Entfernung des
	den Controller steuernden PDAs) reserviert, was 30 Adressen für Busteilnehmer läßt.\\
	Gerichtete und Broadcast-Adressierung sind somit möglich; die Länge der übertragenen Daten ist zudem durch LLO nicht
	eingeschränkt.\\

	Fassen wir einmal kurz die vom Protokoll vorgesehenen Befehle mit ihren relativen Prioritäten zusammen:
	\vspace{0.3cm}\\
	\begin{tabular}{cclp{7cm}}
	{\bf Kürzel} & {\bf Priorität} & {\bf Sender} & {\bf Bedeutung} \\
	\hline
	{\tt SYS} & 3 & Alle 		& Fehlermeldungen, Fehlerbehandlung \\
	{\tt ACK} & 3 & Alle 		& Bestätigung nach Übertragung \\
	{\tt KAL} & 3 & Controller 	& Keep-Alive-Signal (s. \ref{jd-llo-kal}) \\
	{\tt STX} & 2 & Controller 	& Controller $\rightarrow$ Client- Transfer \\
	{\tt RTX} & 1 & Client 		& Client $\rightarrow$ Controller- Transfer \\
	{\tt NOP} & 0 & Controller 	& Busfreigabe \\
	\end{tabular}
	\vspace{0.3cm}

	Betrachten wir nun die wesentlichen Eigenschaften des Protokolls: 

	\subsubsection{Sicherheitsmechanismen gegen Datenverlust}
	Um den Verlust von Datenpaketen wenigstens in den häufigsten Fällen zu bemerken, wird mit jeder Übertragung
	der Inhalt eines 4-Bit-Sequenzzählers versandt, der (bis auf {\tt SYS}-, {\tt KAL}- und {\tt NOP}-Nachrichten) zudem bei jeder
	nicht-Broadcast-Botschaft um eins erhöht wird. Stellt nun der Controller oder der Client beim
	Empfang einer Botschaft ein Nicht-Übereinstimmen der Sequenznummern fest, kann er davon ausgehen, einige Botschaften verloren zu
	haben und diese neu anfordern.\\
	Diese Methode greift offensichtlich nicht immer; bei einer Datenverlustrate von $p$ ist die Wahrscheinlichkeit,
	genau 16 Nachrichten hintereinander zu verlieren, jedoch genau
	$p^{15} * (1-p)$, im Falle von Vielfachen von 16 (also allen Möglichkeiten, in denen ein Datenverlust nicht
	bemerkt würde) somit, für die Aufsummierung der Wahrscheinlichkeiten des Verlustes an der $n$ten Stelle
	$$p_n = p^{16n + 15} * (1-p)$$
	und im Limes
	\begin{equation}
	  \begin{split}
	    \lim_{n \rightarrow \inf} \sum_{k = 0}^n p_k &= (1-p) * p^{15} * \lim_{n \rightarrow \inf} \sum_{k=0}^n p^{16n}\\
	    & = (1-p) * p^{15} * \lim_{n \rightarrow \inf} \frac{p^{16(n+1)} - 1}{p^{16} - 1}\\
	    & = - \frac{(1-p) * p^{15}}{p^{16} - 1}
	  \end{split}
	\end{equation}
	Entsprechend ist bei einem ``realistischen'' Datenverlustwert die Wahrscheinlichkeit für einen kompletten Ausfall
	dieses Mechanismusses vernachlässigbar; selbst bei einem Störfaktor von 0.1 läge die Wahrscheinlichkeit noch bei
	unter $10^{-15}$, sogar ein Störfaktor von 0.9 könnte nur in knapp 2.6\% der Fälle einen Totalausfall dieses
	Sicherungsmechanismusses bewirken.

	\subsubsection{Keep-Alive}\label{jd-llo-kal}
	Dies alles ist im Falle einer kompletten Unterbrechung der Datenleitung jedoch wenig hilfreich. In diesem
	Fall kommt das Keepalive-Signal zum Tragen, das in regelmäßigen Abständen vom Controller auf den Bus geschrieben wird;
	wenn nicht mindestens ein solches {\tt KAL} innerhalb von 0.3s empfangen wurde, sind Klienten dazu angehalten, sich
	selbst in den sicheren Betriebszustand zurückzufahren.

	\subsubsection{Busfreigabe und Client-zu-Controller-Botschaften}
	Da alle vom Controller verwendeten direkten Steuerbefehle Priorität über Client-Befehle haben (mit Ausnahme
	von {\tt ACK} und {\tt SYS}, die von Clients im Rahmen von vom Controller angestoßenen Kommunikationssequenzen
	gesandt werden dürfen, sowie des schweren Systemfehlers {\tt SYS:EGLBL}, der alle Systeme in den sicheren Betriebszustand zwingt),
	muß der Bus vom Controller explizit freigegeben werden. Dies erfolgt, wenn er selbst keine anstehenden Botschaften hat,
	ansonsten in regelmäßigen Intervallen, mittels eines {\tt NOP}-Kommandos, das an Priorität geringer als das Client-nach-Controller-Kommando
	{\tt RTX} ist, das somit-- jedenfalls in der die CAN-Bus-Arbitrierung verwendenden Protokollauslegung-- dieses unterdrückt.\\
	{\tt RTX}- Übertragung läuft analog zur {\tt STX}-Übertragung von Controller zu Client, verwendet jedoch einen eigenen
	Sequenzzähler\footnote{Die historische Begründung dafür liegt im Wunsch, Vollduplex effizient unterstützen zu können; dies war
	relevant für die Verwendung von LLO über die serielle Schnittstelle.}.\\
	{\tt RTX}-Botschaften sind die einzigen Botschaften die, auf vier Prioritisierungsstufen, noch einmal untereinander an Wichtigkeit
	unterscheiden können. Eine genaue Spezifikation der Verwendung dieser Prioritisierung wurde im Rahmen dieser Studienarbeit nicht
	durchgeführt und den endgültig die Geräte programmierenden Mitentwicklern überlassen.

	\subsection{Umsetzung und Tests}
	Das LLO-Protokoll wurde in C zu Testzwecken, aber auch zur seriellen Kommunikation implementiert.
	Die Implementierung auf dem SX-Chip ist zur Zeit noch nicht abgeschlossen.

	\subsection{Einsatz im Proxy}
	Zur Kommunikation zwischen PDA und dem Rest des Busses muß ein ``Proxy'' verwendet werden, eine
	dedizierte Platine, die der Vermittlung zwischen CAN-Bus und der seriellen Schnittstelle des PDAs dient.
	Die Kommunikation zwischen Proxy und PDA findet über die serielle Schnittstelle statt, die beide
	Geräte optional auf Vollduplex betreiben können.\\
	Der Proxy selbst nimmt im Netz noch eine weitere Aufgabe wahr: Er Überprüft das Vorhandensein des PDAs
	und sendet einen Broadcast der Form {\tt SYS:EGLBL} im Falle des Ausbleibens von Antworten des PDAs
	(Systemabsturz, Ausfall, oder Entfernung des Gerätes), um im Falle der Ausschaltung der zentralen
	Kontrollinstanz die angeschlossene Peripherie in den sicheren Betriebszustand zu zwingen.
\newpage

\section{Das LLZ-Protokoll}\footnote{Die vollständige Protokollspezifikation findet sich als Anhang (Sektion \ref{llz-proto}).}

Das LLZ-Protokoll ist ein zustandsbasiertes Protokoll, das eine feste Maximallänge von Botschaften vorsieht (16 Bytes, mit einer Minimallänge von einem Byte) und
eine sehr spezifische Semantik erzwingt. Zudem implementiert es den letzten noch fehlenden Aspekt des Korrektheitskriteriums.

	\subsection{Struktur des Protokolls}

	LLZ definiert Kommunikation zwischen genau zwei Teilnehmern, von denen einer dedizierter Sender und der andere Empfänger ist.
	Beide können Kommunikation initiieren, aber nur der Sender kann eine Antwort ``erzwingen'' lassen; zudem
	ist er auch derjenige, der den Zustand des\\ Empfängers kontrolliert.\\
	Das LLZ-Protokoll wird in mehreren Instanzen verwendet, wobei maximal eine pro Kanal des unterliegenden Protokolles angeboten wird
	(bei LLO werden aufgrund der maximal 30 verwendeten nicht-Controller-\newline Adressen also höchstens 30 Instanzen des Protokolls zugleich ausgeführt).

	\subsubsection{Zustände der LLZ-Empfänger}

	Bevor es jedoch zu einer Ausführung der Datenübertragungen des Protokolles kommt findet die Initialisierung der Busteilnehmer
	statt, bei der der Sender zugleich (möglichst vermittels der Verwendung von Broadcasts eines unterliegenden Protokolles) überprüft,
	wieviele Protokollinstanzen er zu verwenden hat, auf welchen der Kanäle des unterliegenden Protokolles also Empfänger zu erwarten sind.\\

	Clients befinden sich initial im {\tt PRE-INIT}- Zustand, der ihnen jegliche Kommunikation auf dem Bus, mit Ausnahme der Beantwortung
	von Initialisierungssignalen ({\tt INI}) verbietet. Sobald sie ein solches Signal erhalten, gehen sie kurzfristig in einen
	weiteren Zustand ({\tt INIT}), in dem sie eine Überprüfung der Protokollversionsnummer durchführen und, falls kein Fehler auftrat
	(den sie an den Sender kundtun würden, um Sendern, die mehrere Protokollversionen unterstützen, eine entsprechende Suche zu ermöglichen),
	in den {\tt RUNNING}-Zustand über, der ihren normalen Operationsmodus darstellt. Dabei wird ein weiteres Signal an den Sender, {\tt IOK},
	versandt.\\
	Auf Befehl des Senders hin schalten sie sich (eventuell auch schon aus dem {\tt PRE-INIT}-Zustand) in den {\tt DOWN}-Modus, der
	dem sicheren Betriebszustand entspricht.

	\subsubsection{Befehlstabelle}

	Bei der Bestätigung der erfolgreichen Initialisierung vermittels des {\tt IOK}-Blockes wird eine Tabelle der von diesem
	Gerät unterstützten Befehle mitverschickt; diese Tabelle ist bitweise kodiert, wobei in 16 Bytes Raum für 128 Befehle geschaffen wurde.
	Eine spezifische Wahl der Befehlscodes wurde im Rahmen dieser Studienarbeit nur zu Testzwecken durchgeführt und wird späteren
	Implementierern überlassen.\\
	Der Vorteil einer derart versandten Tabelle ist eine eingeschränkte ``Plug-and-Play''- Nachrüstbarkeit der Peripherie.
	Treiber seitens des PDAs\footnote{welche ihre Klienten üblicherweise auf einem bestimmten Kommunikationskanal erwarten} kön-nen mittels
	der Befehlstabelle nun unmittelbar die Verfügbarkeit von Funktionen, die in einer echten Teilmenge der Menge der Versionen
	der Peripherie implementiert wurde, überprüfen, und somit ihre Handlungen oder die von ihrer API angebotene Funktionenmenge
	entsprechend ausrichten.\\
	Alle Kommunikation über den Bus muß durch einen solchen Befehl gekennzeichnet sein, der Befehl darf jedoch noch bis zu 15 Bytes
	an Parametern nehmen\footnote{Dies ist ein Kompromiss an den SX, dessen Datenbänke genau 16 Bytes in Folge fassen}.
	Es gilt eine zusätzliche Einschränkung der Form von Befehlen, die durch die Art des Timeout-Trackings
	bedingt wird: Für alle Befehle $b$ gilt: Für alle Parameterkonfigurationen $p, p^\prime$ gilt, daß der gesamte Zustand des Clients
	unmittelbar nach Ausführung von $b$ mit $p$, ohne, daß zuvor $b$ mit $p^\prime$ ausgeführt wurde, identisch zum Zustand des
	Clients nach der Ausführung von $b$ mit $p^\prime$ gefolgt von $b$ mit $p$ ist.\\
	Das heißt, vereinfacht ausgedrückt, daß die Semantik eines Befehls sich niemals auf Zustände beziehen darf, die der gleiche Befehl
	modifizieren kann.
	\subsubsection{Timeouts}

	Datenübertragungen in LLZ nehmen an, daß sie vollständig und hinreichend korrekt durchgeführt werden oder
	jedenfalls dem Übertragenden eine Nachricht zukommt, wenn bei der
	Übertragung ein nicht korrigierbarer Fehler auftrat (im LLO-Protokoll ist das bei massivsten Datenverlusten
	und fehlschlagender Fehlerbehandlung der Fall). Von der korrekten Überprüfung der Beantwortung von Botschaften
	geht es jedoch nicht aus, daher wird bei jeder Versendung eines Befehls $b$ mit beliebigen Parametern zum
	Zeitpunkt $t$ ein Tupel $(b, t)$ gespeichert, wobei eine (partielle) Zuordnung $\mbox{\it sent}\ b \mapsto t$ resultiert,
	also jedem $b$ ein eindeutiges $t$ (jeweils das aktuellste Datum, da, wie gefordert, gleiche Befehle sich ``gegenseitig überschreiben'')
	zugeordnet ist.\\
	Mit dieser Information wird nun in regelmäßigen Intervallen nach Timeouts von Antworten gesucht und somit der Rest des Korrektheitskriteriums
	erfüllt\footnote{Tatsächlich wird natürlich manchmal umsonst Alarm geschlagen, da unter Umständen nur die Bestätigung verloren gint, aber
	dies haben wir nicht ausgeschlossen}.

	\subsection{Umsetzung und Tests}

	Die Implementierung der Timeouts beschränkt sich auf den PDA; auf der Ebene der SX-Controller, also der Clients,
	ist im Allgemeinen kein ausreichender Speicherplatz für eine Timeout-Fehlerbehandlung; Timeouts treten zudem meist in Situationen auf,
	in denen der Client vom Netz abgetrennt ist, ein Fall, der jedoch bereits durch das periodische Keepalive-Signal
	des LLO-Busses behandelt wird.\\
	Die Implementierung und Anbindung auf Hochsprachenebene wurde abgeschlossen, auf SX-Ebene ist jedoch zum Zeitpunkt des
	Schreibens nur ein Fragment der Implementierung verfügbar.\\
	In der ersten Implementierung ist die Beschränkung von Befehlen zumindest SX-seitig auf solche mit bis zu 5 Bytes an Parametern
	vorgesehen; Notifikationen ({\tt NTF}) und Kommandos ohne Antworten ({\tt CMD})  werden nicht verwendet werden.

\newpage

\section{Fazit}

Im Rahmen des Projektes wurde eine für die Zwecke des Läufers geeignete Kommunikationsstruktur entworfen und getestet, eine
vollständige Implementierung auch auf den Mikrocontrollern war aus verschiedenen Gründen bis zur Fertigstellung dieser Ausfertigung
nicht mehr möglich und muß im Anschluß erfolgen.